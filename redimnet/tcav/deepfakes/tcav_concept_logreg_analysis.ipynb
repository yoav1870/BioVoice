{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# TCAV Concept Logistic Regression Analysis (Speaker Split 15/5)\n",
        "\n",
        "This notebook analyzes a TCAV CSV (like `tcav_ASVspoof_stage4_spoofwrapper.csv`) and trains a **speaker-independent logistic regression** on concept features.\n",
        "\n",
        "It is separated by logic stages:\n",
        "- paths + module loading\n",
        "- CSV job configuration\n",
        "- load / filter / long->wide\n",
        "- speaker split (15 train / 5 test)\n",
        "- train + evaluate logistic regression\n",
        "- interpret concepts (global + per-user)\n",
        "- export outputs\n",
        "\n",
        "Label mapping from your original notebook:\n",
        "- `key=1` -> real (bonafide)\n",
        "- `key=0` -> fake (spoof)\n",
        "- `true label=0` -> real\n",
        "- `true label=1` -> fake\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports + load the analysis functions from the Python script\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "PROJECT_ROOT = Path('/home/SpeakerRec/BioVoice')\n",
        "SCRIPT_DIR = PROJECT_ROOT / 'redimnet' / 'tcav' / 'deepfakes'\n",
        "SCRIPT_PATH = SCRIPT_DIR / 'tcav_concept_logreg_analysis.py'\n",
        "\n",
        "assert SCRIPT_PATH.exists(), f'Missing analysis script: {SCRIPT_PATH}'\n",
        "if str(SCRIPT_DIR) not in sys.path:\n",
        "    sys.path.insert(0, str(SCRIPT_DIR))\n",
        "\n",
        "import tcav_concept_logreg_analysis as mod\n",
        "\n",
        "print('PROJECT_ROOT =', PROJECT_ROOT)\n",
        "print('SCRIPT_PATH =', SCRIPT_PATH)\n",
        "print('Loaded module from =', mod.__file__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# CSV job configuration (separate logic per CSV)\n",
        "# Add more items to CSV_JOBS if you want to analyze multiple TCAV CSV files.\n",
        "\n",
        "CSV_JOBS = [\n",
        "    {\n",
        "        'name': 'stage4_spoofwrapper_pospct',\n",
        "        'csv_path': PROJECT_ROOT / 'data' / 'tcav' / 'tcav_ASVspoof_stage4_spoofwrapper.csv',\n",
        "        'out_dir': PROJECT_ROOT / 'data' / 'tcav' / 'logreg_concept_analysis' / 'stage4_spoofwrapper_pospct',\n",
        "        'feature_metrics': ['positive percentage'],  # or ['magnitude'] or ['both']\n",
        "        'min_cav_acc': None,  # example: 0.5\n",
        "    },\n",
        "]\n",
        "\n",
        "# Split settings\n",
        "NUM_SPEAKERS = 20\n",
        "TRAIN_SPEAKERS = 15\n",
        "TEST_SPEAKERS = 5\n",
        "RANDOM_SEED = 42\n",
        "PREFER_BALANCED_SPEAKERS = True\n",
        "\n",
        "for job in CSV_JOBS:\n",
        "    print(job['name'])\n",
        "    print('  csv_path =', job['csv_path'])\n",
        "    print('  out_dir  =', job['out_dir'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Helper to run one CSV job end-to-end using the functions from the script\n",
        "\n",
        "def run_one_csv_job(job: dict):\n",
        "    feature_metrics = mod._normalize_feature_metrics(job['feature_metrics'])\n",
        "    csv_path = Path(job['csv_path'])\n",
        "    out_dir = Path(job['out_dir'])\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(f'\\n[JOB] {job[\"name\"]}')\n",
        "    print('[1] Load CSV')\n",
        "    df_long = mod.load_tcav_csv(csv_path)\n",
        "    print('    rows =', len(df_long), '| unique speakers =', df_long['speaker_id'].nunique(), '| unique idx =', df_long['idx'].nunique())\n",
        "\n",
        "    print('[2] Optional CAV accuracy concept filter')\n",
        "    df_long_filtered, concept_acc_df = mod.apply_cav_acc_filter(df_long, job.get('min_cav_acc'))\n",
        "    print('    rows after filter =', len(df_long_filtered))\n",
        "\n",
        "    print('[3] Long -> wide (one row per sample)')\n",
        "    df_wide, feature_cols = mod.build_sample_level_dataset(df_long_filtered, feature_metrics)\n",
        "    print('    sample rows =', len(df_wide), '| feature count =', len(feature_cols))\n",
        "\n",
        "    print('[4] Speaker selection + 15/5 split')\n",
        "    selected_speakers = mod.choose_speakers(\n",
        "        df_wide=df_wide,\n",
        "        num_speakers=NUM_SPEAKERS,\n",
        "        seed=RANDOM_SEED,\n",
        "        prefer_balanced=PREFER_BALANCED_SPEAKERS,\n",
        "    )\n",
        "    split_result = mod.split_by_speaker(\n",
        "        df_wide=df_wide,\n",
        "        selected_speakers=selected_speakers,\n",
        "        train_speakers_n=TRAIN_SPEAKERS,\n",
        "        test_speakers_n=TEST_SPEAKERS,\n",
        "        seed=RANDOM_SEED,\n",
        "    )\n",
        "    print('    train speakers:', split_result.train_speakers)\n",
        "    print('    test speakers :', split_result.test_speakers)\n",
        "    print('    train samples =', len(split_result.train_df), '| test samples =', len(split_result.test_df))\n",
        "\n",
        "    print('[5] Train logistic regression + evaluate')\n",
        "    (clf, scaler, X_train, X_test, X_train_scaled, X_test_scaled, y_train, y_test, y_pred, y_prob_fake, metrics) = mod.fit_logreg(\n",
        "        split_result.train_df, split_result.test_df, feature_cols\n",
        "    )\n",
        "    print(json.dumps({k: v for k, v in metrics.items() if k != 'classification_report'}, indent=2))\n",
        "    print(metrics['classification_report'])\n",
        "\n",
        "    print('[6] Build interpretation tables')\n",
        "    coef_df = mod.build_global_importance_table(clf, feature_cols)\n",
        "    class_summary_df = mod.build_class_summary_table(\n",
        "        df_wide[df_wide['speaker_id'].isin(selected_speakers)].copy(), feature_cols\n",
        "    )\n",
        "    pred_df, sample_contrib_long, user_contrib = mod.build_test_predictions_table(\n",
        "        split_result.test_df, feature_cols, X_test_scaled, y_pred, y_prob_fake, clf\n",
        "    )\n",
        "    top_user_df = mod.build_top_concepts_per_user(user_contrib, top_k=3)\n",
        "\n",
        "    print('[7] Export outputs')\n",
        "    df_wide.to_csv(out_dir / 'sample_level_features_all.csv', index=False)\n",
        "    df_wide[df_wide['speaker_id'].isin(selected_speakers)].to_csv(out_dir / 'sample_level_features_selected_20speakers.csv', index=False)\n",
        "    split_result.train_df.to_csv(out_dir / 'train_samples_15speakers.csv', index=False)\n",
        "    split_result.test_df.to_csv(out_dir / 'test_samples_5speakers.csv', index=False)\n",
        "    coef_df.to_csv(out_dir / 'global_concept_coefficients.csv', index=False)\n",
        "    class_summary_df.to_csv(out_dir / 'classwise_concept_summary.csv', index=False)\n",
        "    pred_df.to_csv(out_dir / 'test_predictions.csv', index=False)\n",
        "    sample_contrib_long.to_csv(out_dir / 'test_sample_contributions_long.csv', index=False)\n",
        "    user_contrib.to_csv(out_dir / 'test_user_mean_contributions.csv', index=False)\n",
        "    top_user_df.to_csv(out_dir / 'test_user_top_concepts.csv', index=False)\n",
        "\n",
        "    try:\n",
        "        import joblib\n",
        "        joblib.dump(scaler, out_dir / 'scaler.joblib')\n",
        "        joblib.dump(clf, out_dir / 'logreg.joblib')\n",
        "    except Exception as e:\n",
        "        print('[WARN] joblib save failed:', e)\n",
        "\n",
        "    mod.maybe_save_plots(out_dir, coef_df, user_contrib, split_result.test_speakers)\n",
        "\n",
        "    class ArgsObj:\n",
        "        pass\n",
        "    args_obj = ArgsObj()\n",
        "    args_obj.csv_path = csv_path\n",
        "    args_obj.out_dir = out_dir\n",
        "    args_obj.random_seed = RANDOM_SEED\n",
        "    args_obj.feature_metrics = job['feature_metrics']\n",
        "    args_obj.num_speakers = NUM_SPEAKERS\n",
        "    args_obj.train_speakers = TRAIN_SPEAKERS\n",
        "    args_obj.test_speakers = TEST_SPEAKERS\n",
        "    args_obj.min_cav_acc = job.get('min_cav_acc')\n",
        "    mod.save_run_metadata(out_dir, args_obj, df_long_filtered, df_wide, split_result, feature_cols, concept_acc_df, metrics)\n",
        "\n",
        "    return {\n",
        "        'job': job,\n",
        "        'df_long': df_long,\n",
        "        'df_long_filtered': df_long_filtered,\n",
        "        'df_wide': df_wide,\n",
        "        'feature_cols': feature_cols,\n",
        "        'selected_speakers': selected_speakers,\n",
        "        'split_result': split_result,\n",
        "        'clf': clf,\n",
        "        'scaler': scaler,\n",
        "        'metrics': metrics,\n",
        "        'coef_df': coef_df,\n",
        "        'class_summary_df': class_summary_df,\n",
        "        'pred_df': pred_df,\n",
        "        'sample_contrib_long': sample_contrib_long,\n",
        "        'user_contrib': user_contrib,\n",
        "        'top_user_df': top_user_df,\n",
        "        'out_dir': out_dir,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Run all configured CSV jobs (each CSV gets its own output folder)\n",
        "results = {}\n",
        "for job in CSV_JOBS:\n",
        "    results[job['name']] = run_one_csv_job(job)\n",
        "\n",
        "print('\\nCompleted jobs:', list(results.keys()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Inspect one job quickly (change the key if needed)\n",
        "JOB_NAME = CSV_JOBS[0]['name']\n",
        "r = results[JOB_NAME]\n",
        "\n",
        "print('Job:', JOB_NAME)\n",
        "print('Output folder:', r['out_dir'])\n",
        "print('Test metrics summary:')\n",
        "print(json.dumps({k: v for k, v in r['metrics'].items() if k != 'classification_report'}, indent=2))\n",
        "\n",
        "print('\\nTop global concept coefficients (absolute):')\n",
        "display(r['coef_df'].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Per-user important concepts on test speakers (top concepts)\n",
        "JOB_NAME = CSV_JOBS[0]['name']\n",
        "r = results[JOB_NAME]\n",
        "\n",
        "display(r['top_user_df'].head(30))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Class-wise concept summary (fake vs real means)\n",
        "JOB_NAME = CSV_JOBS[0]['name']\n",
        "r = results[JOB_NAME]\n",
        "\n",
        "display(r['class_summary_df'].sort_values('mean_diff_fake_minus_real', ascending=False).head(10))\n",
        "display(r['class_summary_df'].sort_values('mean_diff_fake_minus_real', ascending=True).head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Notes\n",
        "\n",
        "- This notebook reuses the functions in `redimnet/tcav/deepfakes/tcav_concept_logreg_analysis.py`.\n",
        "- To analyze another TCAV CSV, add another item to `CSV_JOBS` with a different `csv_path` and `out_dir`.\n",
        "- Keep each CSV in a separate `out_dir` so the outputs do not overwrite each other.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}