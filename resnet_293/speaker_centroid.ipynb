{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "331b53c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SpeakerRec/BioVoice/.venvResnet/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/SpeakerRec/BioVoice/.venvResnet/lib/python3.10/site-packages/s3prl/upstream/byol_s/byol_a/common.py:20: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"sox_io\")\n",
      "ESPnet is not installed, cannot use espnet_hubert upstream\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT = /home/SpeakerRec/BioVoice\n",
      "Using device: cuda\n",
      "{'data_type': 'shard', 'dataloader_args': {'batch_size': 32, 'drop_last': True, 'num_workers': 16, 'pin_memory': False, 'prefetch_factor': 8}, 'dataset_args': {'aug_prob': 0.6, 'fbank_args': {'dither': 1.0, 'frame_length': 25, 'frame_shift': 10, 'num_mel_bins': 80}, 'num_frms': 200, 'shuffle': True, 'shuffle_args': {'shuffle_size': 2500}, 'spec_aug': False, 'spec_aug_args': {'max_f': 8, 'max_t': 10, 'num_f_mask': 1, 'num_t_mask': 1, 'prob': 0.6}, 'speed_perturb': True}, 'exp_dir': 'exp/ResNet293-TSTP-emb256-fbank80-num_frms200-aug0.6-spTrue-saFalse-ArcMargin-SGD-epoch150', 'gpus': [0, 1], 'log_batch_interval': 100, 'loss': 'CrossEntropyLoss', 'loss_args': {}, 'margin_scheduler': 'MarginScheduler', 'margin_update': {'epoch_iter': 17062, 'final_margin': 0.2, 'fix_start_epoch': 40, 'increase_start_epoch': 20, 'increase_type': 'exp', 'initial_margin': 0.0, 'update_margin': True}, 'model': 'ResNet293', 'model_args': {'embed_dim': 256, 'feat_dim': 80, 'pooling_func': 'TSTP', 'two_emb_layer': False}, 'model_init': None, 'noise_data': 'data/musan/lmdb', 'num_avg': 2, 'num_epochs': 150, 'optimizer': 'SGD', 'optimizer_args': {'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0001}, 'projection_args': {'easy_margin': False, 'embed_dim': 256, 'num_class': 17982, 'project_type': 'arc_margin', 'scale': 32.0}, 'reverb_data': 'data/rirs/lmdb', 'save_epoch_interval': 5, 'scheduler': 'ExponentialDecrease', 'scheduler_args': {'epoch_iter': 17062, 'final_lr': 5e-05, 'initial_lr': 0.1, 'num_epochs': 150, 'scale_ratio': 1.0, 'warm_from_zero': True, 'warm_up_epoch': 6}, 'seed': 42, 'train_data': 'data/vox2_dev/shard.list', 'train_label': 'data/vox2_dev/utt2spk'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SpeakerRec/BioVoice/.venvResnet/lib/python3.10/site-packages/wespeaker/utils/checkpoint.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-293 loaded from HF\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from wespeaker.cli.speaker import load_model\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parents[0]\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "speaker = load_model(PROJECT_ROOT / \"wespeaker-voxceleb-resnet293-LM\")\n",
    "net = speaker.model\n",
    "net = net.to(DEVICE)\n",
    "\n",
    "print(\"ResNet-293 loaded from HF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8a03e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "AUDIO_ROOT = PROJECT_ROOT / \"data\" / \"wavs\"\n",
    "\n",
    "SPEAKERS = [\"eden\", \"idan\", \"yoav\"]\n",
    "\n",
    "def speaker_from_name(p: Path):\n",
    "    name = p.stem.lower()\n",
    "    for s in SPEAKERS:\n",
    "        if name.startswith(s + \"_\"):\n",
    "            return s\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d9c9a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_with_resnet_293(wav_path, l2_norm: bool = True):\n",
    "    waveform, sr = torchaudio.load(wav_path)\n",
    "    if sr != 16000:\n",
    "        waveform = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)(\n",
    "            waveform\n",
    "        )\n",
    "\n",
    "    # Move waveform to the same device as the model\n",
    "    waveform = waveform.to(DEVICE)\n",
    "\n",
    "    # Use the speaker object's extract_embedding_from_pcm method\n",
    "    embedding = speaker.extract_embedding_from_pcm(waveform, 16000)\n",
    "\n",
    "    if l2_norm:\n",
    "        embedding = embedding / (embedding.norm(p=2) + 1e-12)\n",
    "\n",
    "    return embedding.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "897bca50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90 audio files total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:13<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 90\n",
      "Samples per speaker:\n",
      "eden    30\n",
      "idan    30\n",
      "yoav    30\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>file</th>\n",
       "      <th>speaker</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/SpeakerRec/BioVoice/data/wavs/eden_001.wav</td>\n",
       "      <td>eden_001.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[tensor(0.0569), tensor(0.0265), tensor(0.0244...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/SpeakerRec/BioVoice/data/wavs/eden_002.wav</td>\n",
       "      <td>eden_002.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[tensor(0.0710), tensor(-0.0597), tensor(-0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/SpeakerRec/BioVoice/data/wavs/eden_003.wav</td>\n",
       "      <td>eden_003.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[tensor(0.0058), tensor(-0.0486), tensor(-0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/SpeakerRec/BioVoice/data/wavs/eden_004.wav</td>\n",
       "      <td>eden_004.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[tensor(0.0300), tensor(-0.0372), tensor(0.038...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/SpeakerRec/BioVoice/data/wavs/eden_005.wav</td>\n",
       "      <td>eden_005.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[tensor(0.0802), tensor(-0.0524), tensor(0.052...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               path          file speaker  \\\n",
       "0  /home/SpeakerRec/BioVoice/data/wavs/eden_001.wav  eden_001.wav    eden   \n",
       "1  /home/SpeakerRec/BioVoice/data/wavs/eden_002.wav  eden_002.wav    eden   \n",
       "2  /home/SpeakerRec/BioVoice/data/wavs/eden_003.wav  eden_003.wav    eden   \n",
       "3  /home/SpeakerRec/BioVoice/data/wavs/eden_004.wav  eden_004.wav    eden   \n",
       "4  /home/SpeakerRec/BioVoice/data/wavs/eden_005.wav  eden_005.wav    eden   \n",
       "\n",
       "                                           embedding  \n",
       "0  [tensor(0.0569), tensor(0.0265), tensor(0.0244...  \n",
       "1  [tensor(0.0710), tensor(-0.0597), tensor(-0.02...  \n",
       "2  [tensor(0.0058), tensor(-0.0486), tensor(-0.05...  \n",
       "3  [tensor(0.0300), tensor(-0.0372), tensor(0.038...  \n",
       "4  [tensor(0.0802), tensor(-0.0524), tensor(0.052...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "rows = []\n",
    "\n",
    "# collect BOTH wav and m4a recursively\n",
    "audio_paths = sorted(list(AUDIO_ROOT.rglob(\"*.wav\")) + list(AUDIO_ROOT.rglob(\"*.m4a\")))\n",
    "\n",
    "print(f\"Found {len(audio_paths)} audio files total\")\n",
    "\n",
    "# # optional limits (VERY IMPORTANT)\n",
    "MAX_SPEAKERS = 100\n",
    "MAX_SAMPLES_PER_SPEAKER = 200\n",
    "\n",
    "speaker_counts = {}\n",
    "used_speakers = set()\n",
    "\n",
    "for p in tqdm(audio_paths):\n",
    "    spk = speaker_from_name(p)\n",
    "\n",
    "    # limit number of speakers\n",
    "    if spk not in used_speakers:\n",
    "        if len(used_speakers) >= MAX_SPEAKERS:\n",
    "            continue\n",
    "        used_speakers.add(spk)\n",
    "        speaker_counts[spk] = 0\n",
    "\n",
    "    # limit samples per speaker\n",
    "    if speaker_counts[spk] >= MAX_SAMPLES_PER_SPEAKER:\n",
    "        continue\n",
    "\n",
    "    emb = embed_with_resnet_293(p)\n",
    "    if emb is None:\n",
    "        continue\n",
    "\n",
    "    speaker_counts[spk] += 1\n",
    "\n",
    "    rows.append({\"path\": str(p), \"file\": p.name, \"speaker\": spk, \"embedding\": emb})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "print(\"Total samples:\", len(df))\n",
    "print(\"Samples per speaker:\")\n",
    "print(pd.Series(speaker_counts))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40a198c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed centroids for: ['eden', 'idan', 'yoav']\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "centroids = {}\n",
    "\n",
    "for spk in df[\"speaker\"].unique():\n",
    "    embs = torch.stack(df[df[\"speaker\"] == spk][\"embedding\"].tolist())\n",
    "    centroid = embs.mean(dim=0)\n",
    "    centroid = F.normalize(centroid, dim=0)\n",
    "    centroids[spk] = centroid\n",
    "\n",
    "print(\"Computed centroids for:\", list(centroids.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46b2211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def cosine_to_centroid(emb, centroid):\n",
    "    return float(torch.dot(emb, centroid))\n",
    "\n",
    "df[\"cosine_to_centroid\"] = [\n",
    "    cosine_to_centroid(row.embedding, centroids[row.speaker])\n",
    "    for row in df.itertuples()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d4676df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>file</th>\n",
       "      <th>speaker</th>\n",
       "      <th>embedding</th>\n",
       "      <th>cosine_to_centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/SpeakerRec/BioVoice/data/wavs/eden_029.wav</td>\n",
       "      <td>eden_029.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[tensor(0.0498), tensor(-0.0399), tensor(0.001...</td>\n",
       "      <td>0.846436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/SpeakerRec/BioVoice/data/wavs/eden_022.wav</td>\n",
       "      <td>eden_022.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[tensor(0.0312), tensor(-0.0345), tensor(0.051...</td>\n",
       "      <td>0.842202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/SpeakerRec/BioVoice/data/wavs/eden_014.wav</td>\n",
       "      <td>eden_014.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[tensor(0.0824), tensor(-0.0050), tensor(0.031...</td>\n",
       "      <td>0.837751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/SpeakerRec/BioVoice/data/wavs/eden_020.wav</td>\n",
       "      <td>eden_020.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[tensor(0.0980), tensor(-0.0257), tensor(-0.05...</td>\n",
       "      <td>0.830325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/SpeakerRec/BioVoice/data/wavs/eden_015.wav</td>\n",
       "      <td>eden_015.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[tensor(0.0145), tensor(-0.0732), tensor(0.014...</td>\n",
       "      <td>0.829727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/SpeakerRec/BioVoice/data/wavs/eden_027.wav</td>\n",
       "      <td>eden_027.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[tensor(0.0632), tensor(-0.0183), tensor(0.035...</td>\n",
       "      <td>0.821764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/home/SpeakerRec/BioVoice/data/wavs/eden_005.wav</td>\n",
       "      <td>eden_005.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[tensor(0.0802), tensor(-0.0524), tensor(0.052...</td>\n",
       "      <td>0.816005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/home/SpeakerRec/BioVoice/data/wavs/eden_011.wav</td>\n",
       "      <td>eden_011.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[tensor(0.0543), tensor(-0.0340), tensor(0.072...</td>\n",
       "      <td>0.813013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/SpeakerRec/BioVoice/data/wavs/eden_001.wav</td>\n",
       "      <td>eden_001.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[tensor(0.0569), tensor(0.0265), tensor(0.0244...</td>\n",
       "      <td>0.811855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/SpeakerRec/BioVoice/data/wavs/eden_025.wav</td>\n",
       "      <td>eden_025.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[tensor(0.0589), tensor(-0.0163), tensor(0.016...</td>\n",
       "      <td>0.801858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               path          file speaker  \\\n",
       "0  /home/SpeakerRec/BioVoice/data/wavs/eden_029.wav  eden_029.wav    eden   \n",
       "1  /home/SpeakerRec/BioVoice/data/wavs/eden_022.wav  eden_022.wav    eden   \n",
       "2  /home/SpeakerRec/BioVoice/data/wavs/eden_014.wav  eden_014.wav    eden   \n",
       "3  /home/SpeakerRec/BioVoice/data/wavs/eden_020.wav  eden_020.wav    eden   \n",
       "4  /home/SpeakerRec/BioVoice/data/wavs/eden_015.wav  eden_015.wav    eden   \n",
       "5  /home/SpeakerRec/BioVoice/data/wavs/eden_027.wav  eden_027.wav    eden   \n",
       "6  /home/SpeakerRec/BioVoice/data/wavs/eden_005.wav  eden_005.wav    eden   \n",
       "7  /home/SpeakerRec/BioVoice/data/wavs/eden_011.wav  eden_011.wav    eden   \n",
       "8  /home/SpeakerRec/BioVoice/data/wavs/eden_001.wav  eden_001.wav    eden   \n",
       "9  /home/SpeakerRec/BioVoice/data/wavs/eden_025.wav  eden_025.wav    eden   \n",
       "\n",
       "                                           embedding  cosine_to_centroid  \n",
       "0  [tensor(0.0498), tensor(-0.0399), tensor(0.001...            0.846436  \n",
       "1  [tensor(0.0312), tensor(-0.0345), tensor(0.051...            0.842202  \n",
       "2  [tensor(0.0824), tensor(-0.0050), tensor(0.031...            0.837751  \n",
       "3  [tensor(0.0980), tensor(-0.0257), tensor(-0.05...            0.830325  \n",
       "4  [tensor(0.0145), tensor(-0.0732), tensor(0.014...            0.829727  \n",
       "5  [tensor(0.0632), tensor(-0.0183), tensor(0.035...            0.821764  \n",
       "6  [tensor(0.0802), tensor(-0.0524), tensor(0.052...            0.816005  \n",
       "7  [tensor(0.0543), tensor(-0.0340), tensor(0.072...            0.813013  \n",
       "8  [tensor(0.0569), tensor(0.0265), tensor(0.0244...            0.811855  \n",
       "9  [tensor(0.0589), tensor(-0.0163), tensor(0.016...            0.801858  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "df_sorted = (\n",
    "    df.sort_values([\"speaker\", \"cosine_to_centroid\"], ascending=[True, False])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_sorted.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e1bc25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eden</td>\n",
       "      <td>0.694180</td>\n",
       "      <td>0.846436</td>\n",
       "      <td>0.778943</td>\n",
       "      <td>0.040682</td>\n",
       "      <td>0.152255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>idan</td>\n",
       "      <td>0.814452</td>\n",
       "      <td>0.927562</td>\n",
       "      <td>0.871990</td>\n",
       "      <td>0.025957</td>\n",
       "      <td>0.113110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yoav</td>\n",
       "      <td>0.692299</td>\n",
       "      <td>0.888076</td>\n",
       "      <td>0.802715</td>\n",
       "      <td>0.047097</td>\n",
       "      <td>0.195777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  speaker       min       max      mean       std     range\n",
       "0    eden  0.694180  0.846436  0.778943  0.040682  0.152255\n",
       "1    idan  0.814452  0.927562  0.871990  0.025957  0.113110\n",
       "2    yoav  0.692299  0.888076  0.802715  0.047097  0.195777"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "stats = []\n",
    "\n",
    "for spk in df_sorted[\"speaker\"].unique():\n",
    "    sims = df_sorted[df_sorted[\"speaker\"] == spk][\"cosine_to_centroid\"].values\n",
    "\n",
    "    stats.append(\n",
    "        {\n",
    "            \"speaker\": spk,\n",
    "            \"min\": sims.min(),\n",
    "            \"max\": sims.max(),\n",
    "            \"mean\": sims.mean(),\n",
    "            \"std\": sims.std(),\n",
    "            \"range\": sims.max() - sims.min(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "stats_df = pd.DataFrame(stats)\n",
    "display(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87393187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ranking to: ./speaker_similarity_ranking_team.csv\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "out_path =  \"./speaker_similarity_ranking_team.csv\"\n",
    "df_sorted_out = df_sorted.drop(columns=[\"embedding\"])\n",
    "df_sorted_out.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved ranking to:\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvResnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
