{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from captum.concept import TCAV, Concept\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT = /home/SpeakerRec/BioVoice\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# -------- Project paths / device --------\n",
    "PROJECT_ROOT = Path.cwd().parents[1]\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "ATTR_CSV_PATH = PROJECT_ROOT / \"data\" / \"real_fake_paths.csv\"\n",
    "CONCEPT_ROOT  = Path(PROJECT_ROOT / \"concept\" / \"temp_concepts\")\n",
    "\n",
    "# Pick one layer key you want TCAV on:\n",
    "# LAYER_KEY = \"stage5\"\n",
    "\n",
    "CONCEPT_SAMPLES = 100\n",
    "RANDOM_SAMPLES  = 100\n",
    "BATCH_SIZE_CONCEPT = 1  # keep 1 (safe if variable T)\n",
    "FORCE_TRAIN_CAVS = True  # set True if you want to retrain CAVs\n",
    "\n",
    "# OUT_CSV = Path(f\"stage5_temp_concepts_{LAYER_KEY}.csv\")\n",
    "\n",
    "assert ATTR_CSV_PATH.exists(), f\"Missing {ATTR_CSV_PATH}\"\n",
    "assert CONCEPT_ROOT.exists(), f\"Missing {CONCEPT_ROOT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/SpeakerRec/.cache/torch/hub/IDRnD_ReDimNet_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ReDimNet successfully.\n",
      "ReDimNet spec N_MELS = 72\n"
     ]
    }
   ],
   "source": [
    "redim_model = (\n",
    "    torch.hub.load(\n",
    "        \"IDRnD/ReDimNet\",\n",
    "        \"ReDimNet\",\n",
    "        model_name=\"b5\",\n",
    "        train_type=\"ptn\",\n",
    "        dataset=\"vox2\",\n",
    "    )\n",
    "    .to(DEVICE)\n",
    "    .eval()\n",
    ")\n",
    "print(\"Loaded ReDimNet successfully.\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    dummy_wav = torch.zeros(1, 16000, device=DEVICE)\n",
    "    dummy_mel = redim_model.spec(dummy_wav)  # (1, N_MELS, T)\n",
    "N_MELS = int(dummy_mel.shape[1])\n",
    "print(\"ReDimNet spec N_MELS =\", N_MELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Logistic Regression and Scaler.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MODEL_DIR = PROJECT_ROOT / \"data\" / \"models\" / \"real_vs_fake\"\n",
    "\n",
    "LOGREG_PATH = MODEL_DIR / \"logistic_regression.pkl\"\n",
    "SCALER_PATH = MODEL_DIR / \"scaler.pkl\"\n",
    "\n",
    "assert LOGREG_PATH.exists(), f\"Missing {LOGREG_PATH}\"\n",
    "assert SCALER_PATH.exists(), f\"Missing {SCALER_PATH}\"\n",
    "\n",
    "with open(LOGREG_PATH, \"rb\") as f:\n",
    "    logreg_clf = pickle.load(f)\n",
    "\n",
    "with open(SCALER_PATH, \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "print(\"Loaded Logistic Regression and Scaler.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrapped_model (embedding-only) ready.\n"
     ]
    }
   ],
   "source": [
    "# -------- Wrap ReDimNet -> embeddings --------\n",
    "class ReDimNetEmbeddingWrapper(nn.Module):\n",
    "    \"\"\"\n",
    "    Input:  mel4d [B, 1, N_MELS, T]\n",
    "    Output: embeddings [B, D]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, redim_model, l2_norm_emb: bool = True):\n",
    "        super().__init__()\n",
    "        self.backbone = redim_model.backbone\n",
    "        self.pool = redim_model.pool\n",
    "        self.bn = redim_model.bn\n",
    "        self.linear = redim_model.linear\n",
    "        self.l2_norm_emb = l2_norm_emb\n",
    "\n",
    "    def forward(self, mel4d: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.backbone(mel4d)\n",
    "        x = self.pool(x)\n",
    "        x = self.bn(x)\n",
    "        emb = self.linear(x)\n",
    "        if self.l2_norm_emb:\n",
    "            emb = emb / (emb.norm(p=2, dim=1, keepdim=True) + 1e-12)\n",
    "        return emb\n",
    "\n",
    "\n",
    "wrapped_model = (\n",
    "    ReDimNetEmbeddingWrapper(redim_model, l2_norm_emb=True).to(DEVICE).eval()\n",
    ")\n",
    "\n",
    "print(\"wrapped_model (embedding-only) ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LAYERS = {\n",
    "    # \"stem\":   wrapped_model.backbone.stem[0],\n",
    "    # \"stage0\": wrapped_model.backbone.stage0[2],\n",
    "    # \"stage1\": wrapped_model.backbone.stage1[2],\n",
    "    # \"stage2\": wrapped_model.backbone.stage2[2],\n",
    "    # \"stage3\": wrapped_model.backbone.stage3[2],\n",
    "    \"stage4\": wrapped_model.backbone.stage4[2],\n",
    "    \"stage5\": wrapped_model.backbone.stage5[2],\n",
    "}\n",
    "# assert LAYER_KEY in TARGET_LAYERS, f\"{LAYER_KEY=} not in TARGET_LAYERS: {list(TARGET_LAYERS.keys())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_name_in_model(model: torch.nn.Module, target_module: torch.nn.Module) -> str:\n",
    "    for name, mod in model.named_modules():\n",
    "        if mod is target_module:\n",
    "            return name\n",
    "    raise RuntimeError(\n",
    "        \"Could not find the selected layer module in model.named_modules()\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCAV_DEVICE = cpu\n"
     ]
    }
   ],
   "source": [
    "TCAV_DEVICE = torch.device(\"cpu\")\n",
    "print(\"TCAV_DEVICE =\", TCAV_DEVICE)\n",
    "\n",
    "redim_model = redim_model.to(TCAV_DEVICE).eval()\n",
    "wrapped_model = wrapped_model.to(TCAV_DEVICE).eval()\n",
    "\n",
    "DEVICE = TCAV_DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptNPYDataset(Dataset):\n",
    "    def __init__(self, concept_dir: Path, limit: int | None = None):\n",
    "        self.files = sorted(concept_dir.glob(\"*.npy\"))\n",
    "        if not self.files:\n",
    "            raise RuntimeError(f\"No .npy found in {concept_dir}\")\n",
    "        if limit is not None:\n",
    "            self.files = self.files[:limit]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mel = np.load(self.files[idx]).astype(np.float32)  # (N_MELS, T)\n",
    "        if mel.shape[0] != N_MELS:\n",
    "            raise RuntimeError(f\"{self.files[idx].name}: expected {N_MELS} bins, got {mel.shape}\")\n",
    "        x = torch.from_numpy(mel).unsqueeze(0)  # (1, N_MELS, T) on CPU\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def infer_frames_for_random(concept_dirs: list[Path]) -> int:\n",
    "    for d in concept_dirs:\n",
    "        f = next(d.glob(\"*.npy\"), None)\n",
    "        if f is not None:\n",
    "            mel = np.load(f)\n",
    "            return int(mel.shape[1])\n",
    "    raise RuntimeError(\"Could not infer frames from concept dirs\")\n",
    "\n",
    "class RandomMelDataset(Dataset):\n",
    "    def __init__(self, n_samples: int, frames: int):\n",
    "        self.n_samples = n_samples\n",
    "        self.frames = frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mel = torch.randn(N_MELS, self.frames, dtype=torch.float32)  \n",
    "        return mel.unsqueeze(0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts: ['long_constant_thick', 'long_constant_thick_Vibrato', 'long_dropping_flat_thick', 'long_dropping_flat_thick_Vibrato', 'long_dropping_steep_thick', 'long_dropping_steep_thin', 'long_rising_flat_thick', 'long_rising_steep_thick', 'long_rising_steep_thin', 'short_constant_thick', 'short_dropping_steep_thick', 'short_dropping_steep_thin', 'short_rising_steep_thick', 'short_rising_steep_thin']\n",
      "Using fixed frames for TCAV (from concepts): 304\n"
     ]
    }
   ],
   "source": [
    "concept_dirs = sorted([d for d in CONCEPT_ROOT.iterdir() if d.is_dir()])\n",
    "if not concept_dirs:\n",
    "    raise RuntimeError(f\"No concept folders in {CONCEPT_ROOT}\")\n",
    "\n",
    "concept_names = [d.name for d in concept_dirs]\n",
    "print(\"Concepts:\", concept_names)\n",
    "\n",
    "TARGET_FRAMES = infer_frames_for_random(concept_dirs)\n",
    "print(\"Using fixed frames for TCAV (from concepts):\", TARGET_FRAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/concept/_utils/classifier.py:130: UserWarning: Using default classifier for TCAV which keeps input both train and test datasets in the memory. Consider defining your own classifier that doesn't rely heavily on memory, for large number of concepts, by extending `Classifer` abstract class\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# -------- Prepare concepts (same for all layers) --------\n",
    "positive_concepts = []\n",
    "for idx, cdir in enumerate(concept_dirs):\n",
    "    ds = ConceptNPYDataset(cdir, limit=CONCEPT_SAMPLES)\n",
    "    dl = DataLoader(ds, batch_size=BATCH_SIZE_CONCEPT, shuffle=False, num_workers=0)\n",
    "    positive_concepts.append(Concept(id=idx, name=cdir.name, data_iter=dl))\n",
    "\n",
    "rand_ds = RandomMelDataset(n_samples=RANDOM_SAMPLES, frames=TARGET_FRAMES)\n",
    "rand_dl = DataLoader(rand_ds, batch_size=BATCH_SIZE_CONCEPT, shuffle=False, num_workers=0)\n",
    "random_concept = Concept(id=len(positive_concepts), name=\"random\", data_iter=rand_dl)\n",
    "\n",
    "experimental_sets = [[c, random_concept] for c in positive_concepts]\n",
    "\n",
    "# -------- Loop over all layers --------\n",
    "all_tcav_results = {}  # Store results for each layer\n",
    "all_acc_dfs = []       # Accumulate accuracy DataFrames\n",
    "\n",
    "for layer_key, layer_module in TARGET_LAYERS.items():\n",
    "    \n",
    "    # Resolve layer name for Captum\n",
    "    layer_name = module_name_in_model(wrapped_model, layer_module)\n",
    "    # Initialize TCAV for this layer\n",
    "    tcav = TCAV(wrapped_model, [layer_name], test_split_ratio=0.33)\n",
    "    all_tcav_results[layer_key] = tcav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing CAV accuracies for all layers...\n",
      "  Computing CAVs for stage4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/models/linear_model/train.py:350: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  bias_values = torch.FloatTensor([sklearn_model.intercept_]).to(  # type: ignore\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found 14 CAV accuracies\n",
      "  Computing CAVs for stage5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n",
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/_utils/av.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  av = torch.load(fl)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found 14 CAV accuracies\n",
      "\n",
      "Total CAV accuracies: 28\n",
      "  layer_key                      concept name         layer name   cav acc\n",
      "0    stage4               long_constant_thick  backbone.stage4.2  0.365385\n",
      "1    stage4       long_constant_thick_Vibrato  backbone.stage4.2  0.423077\n",
      "2    stage4          long_dropping_flat_thick  backbone.stage4.2  0.346154\n",
      "3    stage4  long_dropping_flat_thick_Vibrato  backbone.stage4.2  0.346154\n",
      "4    stage4         long_dropping_steep_thick  backbone.stage4.2  0.365385\n",
      "5    stage4          long_dropping_steep_thin  backbone.stage4.2  0.461538\n",
      "6    stage4            long_rising_flat_thick  backbone.stage4.2  0.423077\n",
      "7    stage4           long_rising_steep_thick  backbone.stage4.2  0.480769\n",
      "8    stage4            long_rising_steep_thin  backbone.stage4.2  0.307692\n",
      "9    stage4              short_constant_thick  backbone.stage4.2  0.500000\n"
     ]
    }
   ],
   "source": [
    "def compute_cav_acc_df(tcav: TCAV, positive_concepts: list[Concept], random_concept: Concept, layer_key: str) -> pd.DataFrame:\n",
    "    cavs_dict = tcav.compute_cavs([[c, random_concept] for c in positive_concepts], force_train=FORCE_TRAIN_CAVS)\n",
    "\n",
    "    rows = []\n",
    "    for concepts_key, layer_map in cavs_dict.items():\n",
    "        try:\n",
    "            pos_id = int(str(concepts_key).split(\"-\")[0])\n",
    "        except Exception:\n",
    "            continue\n",
    "        if not (0 <= pos_id < len(positive_concepts)):\n",
    "            continue\n",
    "        concept_name = positive_concepts[pos_id].name\n",
    "\n",
    "        for layer_name, cav_obj in layer_map.items():\n",
    "            if cav_obj is None or cav_obj.stats is None:\n",
    "                continue\n",
    "            acc = cav_obj.stats.get(\"accs\", None)\n",
    "            if acc is None:\n",
    "                acc = cav_obj.stats.get(\"acc\", None)\n",
    "            if isinstance(acc, torch.Tensor):\n",
    "                acc = acc.detach().cpu().item()\n",
    "            rows.append({\n",
    "                \"layer_key\": layer_key,\n",
    "                \"concept name\": concept_name,\n",
    "                \"layer name\": layer_name,\n",
    "                \"cav acc\": float(acc) if acc is not None else np.nan,\n",
    "            })\n",
    "    return pd.DataFrame(rows, columns=[\"layer_key\", \"concept name\", \"layer name\", \"cav acc\"])\n",
    "\n",
    "# Compute CAV accuracies for all layers\n",
    "print(\"Computing CAV accuracies for all layers...\")\n",
    "for layer_key, tcav in all_tcav_results.items():\n",
    "    print(f\"  Computing CAVs for {layer_key}...\")\n",
    "    acc_df = compute_cav_acc_df(tcav, positive_concepts, random_concept, layer_key)\n",
    "    all_acc_dfs.append(acc_df)\n",
    "    print(f\"    Found {len(acc_df)} CAV accuracies\")\n",
    "\n",
    "acc_df_combined = pd.concat(all_acc_dfs, ignore_index=True) if all_acc_dfs else pd.DataFrame()\n",
    "print(f\"\\nTotal CAV accuracies: {len(acc_df_combined)}\")\n",
    "if not acc_df_combined.empty:\n",
    "    print(acc_df_combined.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_mel_frames(mel_3d: torch.Tensor, target_frames: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    mel_3d: (1, N_MELS, T)\n",
    "    returns: (1, N_MELS, target_frames)\n",
    "    \"\"\"\n",
    "    T = int(mel_3d.shape[-1])\n",
    "    if T == target_frames:\n",
    "        return mel_3d\n",
    "    if T > target_frames:\n",
    "        start = (T - target_frames) // 2\n",
    "        return mel_3d[..., start:start + target_frames]\n",
    "    pad = target_frames - T\n",
    "    return F.pad(mel_3d, (0, pad), mode=\"constant\", value=0.0)\n",
    "\n",
    "def wav_path_to_mel4d(path: Path) -> torch.Tensor:\n",
    "    wav, sr = torchaudio.load(str(path))\n",
    "    wav = wav[:1, :].float().to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        mel = redim_model.spec(wav)          # (1, N_MELS, T)\n",
    "    mel = fix_mel_frames(mel, TARGET_FRAMES) # (1, N_MELS, TARGET_FRAMES)\n",
    "    return mel.unsqueeze(0)                  # (1, 1, N_MELS, TARGET_FRAMES)\n",
    "\n",
    "def predict_speaker(path: Path) -> tuple[str, float]:\n",
    "    x = wav_path_to_mel4d(path)\n",
    "    with torch.no_grad():\n",
    "        logits = wrapped_model(x)            # (1, num_speakers)\n",
    "        probs = F.softmax(logits, dim=1)[0]\n",
    "        pred_id = int(torch.argmax(probs).item())\n",
    "        pred_name = id_to_speaker[pred_id]\n",
    "        pred_prob = float(probs[pred_id].item())\n",
    "    return pred_name, pred_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SpeakerRec/BioVoice/.venv/lib/python3.10/site-packages/captum/concept/_core/cav.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  save_dict = torch.load(cavs_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved â†’ tcav_real_vs_fake_all_layers.csv\n",
      "Results shape: (5040, 8)\n",
      "\n",
      "First few rows:\n",
      "                                               path layer_key  \\\n",
      "0  /home/SpeakerRec/BioVoice/data/wavs/idan_001.wav    stage4   \n",
      "1  /home/SpeakerRec/BioVoice/data/wavs/idan_001.wav    stage4   \n",
      "2  /home/SpeakerRec/BioVoice/data/wavs/idan_001.wav    stage4   \n",
      "3  /home/SpeakerRec/BioVoice/data/wavs/idan_001.wav    stage4   \n",
      "4  /home/SpeakerRec/BioVoice/data/wavs/idan_001.wav    stage4   \n",
      "\n",
      "                       concept name         layer name  positive percentage  \\\n",
      "0               long_constant_thick  backbone.stage4.2                  0.0   \n",
      "1       long_constant_thick_Vibrato  backbone.stage4.2                  0.0   \n",
      "2          long_dropping_flat_thick  backbone.stage4.2                  0.0   \n",
      "3  long_dropping_flat_thick_Vibrato  backbone.stage4.2                  0.0   \n",
      "4         long_dropping_steep_thick  backbone.stage4.2                  0.0   \n",
      "\n",
      "   magnitude  true label   cav acc  \n",
      "0  -0.009237           0  0.365385  \n",
      "1  -0.010030           0  0.423077  \n",
      "2  -0.009407           0  0.346154  \n",
      "3  -0.011119           0  0.346154  \n",
      "4  -0.011931           0  0.365385  \n"
     ]
    }
   ],
   "source": [
    "df_attr = pd.read_csv(ATTR_CSV_PATH)\n",
    "\n",
    "# Expect columns: path, label (0=real, 1=fake)\n",
    "if \"path\" not in df_attr.columns or \"label\" not in df_attr.columns:\n",
    "    raise RuntimeError(\n",
    "        f\"CSV must contain columns ['path','label']. Got: {list(df_attr.columns)}\"\n",
    "    )\n",
    "\n",
    "rows = []\n",
    "\n",
    "TARGET_CLASS = 1  # Fake\n",
    "\n",
    "for _, r in df_attr.iterrows():\n",
    "    path = Path(r[\"path\"])\n",
    "    true_label = int(r[\"label\"])\n",
    "\n",
    "    if not path.exists():\n",
    "        continue\n",
    "\n",
    "    # Prepare input\n",
    "    x = wav_path_to_mel4d(path)\n",
    "\n",
    "    # Loop over all layers and collect TCAV scores\n",
    "    for layer_key, tcav in all_tcav_results.items():\n",
    "        score_for_label = tcav.interpret(\n",
    "            inputs=x,\n",
    "            experimental_sets=experimental_sets,\n",
    "            target=TARGET_CLASS,\n",
    "        )\n",
    "\n",
    "        for exp_key, layer_dict in score_for_label.items():\n",
    "            try:\n",
    "                pos_idx = int(str(exp_key).split(\"-\")[0])\n",
    "            except Exception:\n",
    "                continue\n",
    "            if not (0 <= pos_idx < len(positive_concepts)):\n",
    "                continue\n",
    "\n",
    "            concept_name = positive_concepts[pos_idx].name\n",
    "\n",
    "            for layer_name, metrics in layer_dict.items():\n",
    "                sc = metrics.get(\"sign_count\")\n",
    "                mg = metrics.get(\"magnitude\")\n",
    "                if sc is None or mg is None:\n",
    "                    continue\n",
    "\n",
    "                if isinstance(sc, torch.Tensor):\n",
    "                    sc = sc.detach().cpu().tolist()\n",
    "                if isinstance(mg, torch.Tensor):\n",
    "                    mg = mg.detach().cpu().tolist()\n",
    "\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"path\": str(path),\n",
    "                        \"layer_key\": layer_key,\n",
    "                        \"concept name\": concept_name,\n",
    "                        \"layer name\": layer_name,\n",
    "                        \"positive percentage\": float(sc[0]),\n",
    "                        \"magnitude\": float(mg[0]),\n",
    "                        \"true label\": true_label,  # 0=real, 1=fake\n",
    "                    }\n",
    "                )\n",
    "\n",
    "df_tcav = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\n",
    "        \"path\",\n",
    "        \"layer_key\",\n",
    "        \"concept name\",\n",
    "        \"layer name\",\n",
    "        \"positive percentage\",\n",
    "        \"magnitude\",\n",
    "        \"true label\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Merge with CAV accuracies\n",
    "df_tcav = df_tcav.merge(\n",
    "    acc_df_combined,\n",
    "    on=[\"layer_key\", \"concept name\", \"layer name\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "OUT_CSV = Path(\"tcav_real_vs_fake_all_layers.csv\")\n",
    "df_tcav.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved â†’ {OUT_CSV}\")\n",
    "print(f\"Results shape: {df_tcav.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df_tcav.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
