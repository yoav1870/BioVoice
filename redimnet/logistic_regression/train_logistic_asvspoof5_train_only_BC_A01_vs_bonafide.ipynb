{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASVspoof5 Train-Only Probe (B -> C): Bonafide vs Each Spoof System (`A01-A08`)\n",
    "\n",
    "This notebook runs the same binary task repeatedly for each train spoof system:\n",
    "- class `0` = bonafide\n",
    "- class `1` = spoof for one `system_id` (e.g., `A01`)\n",
    "\n",
    "For every system in `A01..A08`:\n",
    "- train on `group B`\n",
    "- test on `group C`\n",
    "- save metrics + predictions\n",
    "\n",
    "This gives an algorithm-specific comparison table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "PROJECT_ROOT = Path(\"/home/SpeakerRec/BioVoice\")\n",
    "MANIFEST_PATH = PROJECT_ROOT / \"redimnet\" / \"tcav\" / \"deepfakes\" / \"asvspoof5\" / \"asvspoof5_train_only_selected_utterances_plan.csv\"\n",
    "SUBSET_AUDIO_ROOT = PROJECT_ROOT / \"data\" / \"datasets\" / \"asvspoof5_train_only_subset_audio\"\n",
    "\n",
    "EMBED_CACHE_DIR = PROJECT_ROOT / \"data\" / \"embeddings\" / \"asvspoof5_train_only_abc\"\n",
    "EMBED_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "print(\"MANIFEST_PATH:\", MANIFEST_PATH)\n",
    "print(\"SUBSET_AUDIO_ROOT:\", SUBSET_AUDIO_ROOT)\n",
    "\n",
    "SYSTEM_IDS = [f'A{i:02d}' for i in range(1, 9)]\n",
    "OUT_DIR = PROJECT_ROOT / 'data' / 'models' / 'asvspoof5_train_only_probe_BC_all_systems_vs_bonafide'\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FORCE_RECOMPUTE_EMBEDDINGS = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_MAP = {\"bonafide\": 0, \"spoof\": 1}\n",
    "\n",
    "\n",
    "def build_audio_path(row, subset_root: Path) -> Path:\n",
    "    return subset_root / str(row[\"group\"]) / str(row[\"label\"]) / f\"{row['utt_id']}.flac\"\n",
    "\n",
    "\n",
    "def load_manifest(manifest_path: Path, subset_root: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(manifest_path)\n",
    "    df = df.copy()\n",
    "    df[\"label_str\"] = df[\"label\"].astype(str)\n",
    "    df[\"label_id\"] = df[\"label_str\"].map(LABEL_MAP).astype(int)\n",
    "    df[\"audio_path\"] = df.apply(lambda r: str(build_audio_path(r, subset_root)), axis=1)\n",
    "    df[\"audio_exists\"] = df[\"audio_path\"].map(lambda p: Path(p).exists())\n",
    "    return df\n",
    "\n",
    "\n",
    "def embed_with_redim(model, wav_path: str, device: str) -> np.ndarray:\n",
    "    wav, sr = torchaudio.load(wav_path)\n",
    "    if sr != 16000:\n",
    "        wav = torchaudio.functional.resample(wav, sr, 16000)\n",
    "    if wav.shape[0] > 1:\n",
    "        wav = wav[:1, :]\n",
    "    wav = wav.to(device)\n",
    "    with torch.no_grad():\n",
    "        emb = model(wav)\n",
    "    return emb.squeeze(0).detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "\n",
    "def extract_embeddings_for_df(df: pd.DataFrame, model, device: str, cache_npz: Path, force_recompute: bool = False):\n",
    "    if cache_npz.exists() and not force_recompute:\n",
    "        payload = np.load(cache_npz, allow_pickle=True)\n",
    "        emb = payload[\"X\"]\n",
    "        utt_ids = payload[\"utt_ids\"].astype(str)\n",
    "        cache_df = pd.DataFrame({\"utt_id\": utt_ids, \"_emb_idx\": np.arange(len(utt_ids))})\n",
    "        merged = df.merge(cache_df, on=\"utt_id\", how=\"left\", validate=\"one_to_one\")\n",
    "        if merged[\"_emb_idx\"].isna().any():\n",
    "            missing = merged.loc[merged[\"_emb_idx\"].isna(), \"utt_id\"].tolist()[:10]\n",
    "            raise RuntimeError(f\"Cache missing utt_ids, examples: {missing}\")\n",
    "        return emb[merged[\"_emb_idx\"].astype(int).to_numpy()]\n",
    "\n",
    "    vecs, ids = [], []\n",
    "    for rec in tqdm(df.to_dict(\"records\"), desc=f\"Embedding {len(df)} samples\"):\n",
    "        vecs.append(embed_with_redim(model, str(rec[\"audio_path\"]), device))\n",
    "        ids.append(str(rec[\"utt_id\"]))\n",
    "    X = np.stack(vecs).astype(np.float32)\n",
    "    np.savez_compressed(cache_npz, X=X, utt_ids=np.array(ids, dtype=object))\n",
    "    return X\n",
    "\n",
    "\n",
    "def train_and_eval_logreg(X_train, y_train, X_test, y_test, class_weight=\"balanced\"):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "    clf = LogisticRegression(max_iter=2000, class_weight=class_weight, random_state=42)\n",
    "    clf.fit(X_train_s, y_train)\n",
    "    p_train = clf.predict_proba(X_train_s)[:, 1]\n",
    "    p_test = clf.predict_proba(X_test_s)[:, 1]\n",
    "    yhat_train = (p_train >= 0.5).astype(int)\n",
    "    yhat_test = (p_test >= 0.5).astype(int)\n",
    "    metrics = {\n",
    "        'train_accuracy': float(accuracy_score(y_train, yhat_train)),\n",
    "        'test_accuracy': float(accuracy_score(y_test, yhat_test)),\n",
    "        'train_auc': float(roc_auc_score(y_train, p_train)) if len(np.unique(y_train))==2 else None,\n",
    "        'test_auc': float(roc_auc_score(y_test, p_test)) if len(np.unique(y_test))==2 else None,\n",
    "        'train_confusion_matrix': confusion_matrix(y_train, yhat_train).tolist(),\n",
    "        'test_confusion_matrix': confusion_matrix(y_test, yhat_test).tolist(),\n",
    "        'train_classification_report': classification_report(y_train, yhat_train, output_dict=True, zero_division=0),\n",
    "        'test_classification_report': classification_report(y_test, yhat_test, output_dict=True, zero_division=0),\n",
    "    }\n",
    "    return scaler, clf, p_train, p_test, yhat_train, yhat_test, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redim_model = (\n",
    "    torch.hub.load(\n",
    "        \"IDRnD/ReDimNet\",\n",
    "        \"ReDimNet\",\n",
    "        model_name=\"b5\",\n",
    "        train_type=\"ptn\",\n",
    "        dataset=\"vox2\",\n",
    "    )\n",
    "    .to(DEVICE)\n",
    "    .eval()\n",
    ")\n",
    "print(\"Loaded ReDimNet on\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_df = load_manifest(MANIFEST_PATH, SUBSET_AUDIO_ROOT)\n",
    "bc_df = manifest_df[manifest_df['group'].isin(['B', 'C'])].copy().reset_index(drop=True)\n",
    "print('B/C rows:', len(bc_df))\n",
    "print('Missing audio:', int((~bc_df['audio_exists']).sum()))\n",
    "print('Systems in spoof rows:', sorted(bc_df.loc[bc_df['label_str']=='spoof', 'system_id'].unique().tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_rows = []\n",
    "all_pred_parts = []\n",
    "\n",
    "for target_system in SYSTEM_IDS:\n",
    "    print(f'\\\\n=== {target_system} vs bonafide ===')\n",
    "    mask_task = (bc_df['label_str'].eq('bonafide')) | ((bc_df['label_str'].eq('spoof')) & (bc_df['system_id'].eq(target_system)))\n",
    "    task_df = bc_df[mask_task].copy().reset_index(drop=True)\n",
    "    task_df['task_label_id'] = np.where(task_df['label_str'].eq('bonafide'), 0, 1).astype(int)\n",
    "\n",
    "    print(task_df.groupby(['group','label_str','system_id']).size())\n",
    "    cache_npz = EMBED_CACHE_DIR / f'embeddings_BC_{target_system}_vs_bonafide.npz'\n",
    "    X_task = extract_embeddings_for_df(task_df[['utt_id','audio_path']], redim_model, DEVICE, cache_npz, force_recompute=FORCE_RECOMPUTE_EMBEDDINGS)\n",
    "    y_task = task_df['task_label_id'].to_numpy().astype(int)\n",
    "\n",
    "    train_mask = task_df['group'].eq('B').to_numpy()\n",
    "    test_mask = task_df['group'].eq('C').to_numpy()\n",
    "    X_train, y_train = X_task[train_mask], y_task[train_mask]\n",
    "    X_test, y_test = X_task[test_mask], y_task[test_mask]\n",
    "\n",
    "    scaler, clf, p_train, p_test, yhat_train, yhat_test, metrics = train_and_eval_logreg(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    sys_dir = OUT_DIR / target_system\n",
    "    sys_dir.mkdir(parents=True, exist_ok=True)\n",
    "    with open(sys_dir / 'scaler.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    with open(sys_dir / 'logistic_regression.pkl', 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "    (sys_dir / 'metrics.json').write_text(json.dumps(metrics, indent=2), encoding='utf-8')\n",
    "\n",
    "    pred_df = task_df[['group','speaker_id','utt_id','label_str','label_id','system_id','task_label_id']].copy()\n",
    "    pred_df['target_system'] = target_system\n",
    "    pred_df['split'] = np.where(train_mask, 'train_B', 'test_C')\n",
    "    pred_df['prob_target_spoof'] = np.concatenate([p_train, p_test])\n",
    "    pred_df['pred_task_label_id'] = np.concatenate([yhat_train, yhat_test])\n",
    "    pred_df.to_csv(sys_dir / f'predictions_{target_system}_vs_bonafide.csv', index=False)\n",
    "    all_pred_parts.append(pred_df)\n",
    "\n",
    "    summary_rows.append({\n",
    "        'target_system': target_system,\n",
    "        'train_samples': int(len(y_train)),\n",
    "        'test_samples': int(len(y_test)),\n",
    "        'train_accuracy': metrics['train_accuracy'],\n",
    "        'test_accuracy': metrics['test_accuracy'],\n",
    "        'train_auc': metrics['train_auc'],\n",
    "        'test_auc': metrics['test_auc'],\n",
    "        'test_bonafide_n': int((y_test == 0).sum()),\n",
    "        'test_spoof_n': int((y_test == 1).sum()),\n",
    "        'test_cm_00': int(metrics['test_confusion_matrix'][0][0]),\n",
    "        'test_cm_01': int(metrics['test_confusion_matrix'][0][1]),\n",
    "        'test_cm_10': int(metrics['test_confusion_matrix'][1][0]),\n",
    "        'test_cm_11': int(metrics['test_confusion_matrix'][1][1]),\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values('target_system')\n",
    "summary_df.to_csv(OUT_DIR / 'all_systems_metrics_summary.csv', index=False)\n",
    "if all_pred_parts:\n",
    "    pd.concat(all_pred_parts, ignore_index=True).to_csv(OUT_DIR / 'all_systems_predictions_combined.csv', index=False)\n",
    "\n",
    "print('Saved summary ->', OUT_DIR / 'all_systems_metrics_summary.csv')\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: compare systems on test accuracy / test AUC\n",
    "summary_df = pd.read_csv(OUT_DIR / 'all_systems_metrics_summary.csv')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.bar(summary_df['target_system'], summary_df['test_accuracy'], color='#f28e2b')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlabel('System ID')\n",
    "ax.set_ylabel('Test Accuracy (C)')\n",
    "ax.set_title('Bonafide vs Spoof-System Accuracy by Target System')\n",
    "for i, v in enumerate(summary_df['test_accuracy']):\n",
    "    ax.text(i, v + 0.015, f'{v:.2f}', ha='center', fontsize=8)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "if summary_df['test_auc'].notna().any():\n",
    "    fig, ax = plt.subplots(figsize=(8,4))\n",
    "    ax.plot(summary_df['target_system'], summary_df['test_auc'], marker='o')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xlabel('System ID')\n",
    "    ax.set_ylabel('Test AUC (C)')\n",
    "    ax.set_title('Bonafide vs Spoof-System AUC by Target System')\n",
    "    plt.tight_layout(); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}