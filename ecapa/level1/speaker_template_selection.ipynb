{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5576fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yoav1\\OneDrive\\Desktop\\לימודים\\year4\\final\\BioVoice\\venv\\lib\\site-packages\\speechbrain\\utils\\checkpoints.py:145: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(path, map_location=device), strict=False\n",
      "c:\\Users\\yoav1\\OneDrive\\Desktop\\לימודים\\year4\\final\\BioVoice\\venv\\lib\\site-packages\\speechbrain\\processing\\features.py:1218: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  stats = torch.load(path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import torchaudio\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "import itertools\n",
    "import ast\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load pretrained ECAPA model\n",
    "classifier = EncoderClassifier.from_hparams(\n",
    "    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
    "    savedir=\"ecapa_pretrained\"\n",
    ").to(device)\n",
    "\n",
    "def get_embedding(wav_path):\n",
    "    \"\"\"Returns a normalized ECAPA embedding vector [emb_dim].\"\"\"\n",
    "    signal, fs = torchaudio.load(str(wav_path))\n",
    "    if fs != 16000:\n",
    "        signal = torchaudio.functional.resample(signal, fs, 16000)\n",
    "    signal = signal.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emb = classifier.encode_batch(signal)   # shape [1, 1, emb_dim]\n",
    "\n",
    "    emb = emb.squeeze(0).squeeze(0)\n",
    "    emb = F.normalize(emb, p=2, dim=0) # L2 normalization\n",
    "    return emb.cpu()\n",
    "\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "162612e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>true_label</th>\n",
       "      <th>embedding_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data\\eden_001.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[0.0511067770421505, 0.03551109880208969, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data\\eden_002.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[0.18112494051456451, 0.013891077600419521, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data\\eden_003.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[0.09115337580442429, -0.10557050257921219, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data\\eden_004.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[0.1183476597070694, -0.037616558372974396, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data\\eden_005.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>[0.11517681926488876, -0.0064055174589157104, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                path true_label  \\\n",
       "0  data\\eden_001.wav       eden   \n",
       "1  data\\eden_002.wav       eden   \n",
       "2  data\\eden_003.wav       eden   \n",
       "3  data\\eden_004.wav       eden   \n",
       "4  data\\eden_005.wav       eden   \n",
       "\n",
       "                                    embedding_vector  \n",
       "0  [0.0511067770421505, 0.03551109880208969, 0.02...  \n",
       "1  [0.18112494051456451, 0.013891077600419521, -0...  \n",
       "2  [0.09115337580442429, -0.10557050257921219, 0....  \n",
       "3  [0.1183476597070694, -0.037616558372974396, 0....  \n",
       "4  [0.11517681926488876, -0.0064055174589157104, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Extract ECAPA embeddings for ALL wav files in data_dir\n",
    "\n",
    "data_dir = Path(\"./data\")\n",
    "wav_paths = sorted(list(data_dir.glob(\"*.wav\")))\n",
    "\n",
    "rows = []\n",
    "emb_dict = {}  \n",
    "for wav in wav_paths:\n",
    "    emb = get_embedding(wav)\n",
    "    true_label = wav.stem.split(\"_\")[0]   \n",
    "    \n",
    "    emb_dict[str(wav)] = emb\n",
    "    rows.append({\n",
    "        \"path\": str(wav),\n",
    "        \"true_label\": true_label,\n",
    "        \"embedding_vector\": emb.numpy().tolist()  \n",
    "    })\n",
    "\n",
    "df_emb = pd.DataFrame(rows)\n",
    "df_emb.to_csv(\"users_embeddings.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "df_emb.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c0dfe59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>wav1</th>\n",
       "      <th>wav2</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eden</td>\n",
       "      <td>data\\eden_001.wav</td>\n",
       "      <td>data\\eden_002.wav</td>\n",
       "      <td>0.474616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eden</td>\n",
       "      <td>data\\eden_001.wav</td>\n",
       "      <td>data\\eden_003.wav</td>\n",
       "      <td>0.436774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eden</td>\n",
       "      <td>data\\eden_001.wav</td>\n",
       "      <td>data\\eden_004.wav</td>\n",
       "      <td>0.558711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eden</td>\n",
       "      <td>data\\eden_001.wav</td>\n",
       "      <td>data\\eden_005.wav</td>\n",
       "      <td>0.604544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eden</td>\n",
       "      <td>data\\eden_001.wav</td>\n",
       "      <td>data\\eden_006.wav</td>\n",
       "      <td>0.587780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  speaker               wav1               wav2  cosine_similarity\n",
       "0    eden  data\\eden_001.wav  data\\eden_002.wav           0.474616\n",
       "1    eden  data\\eden_001.wav  data\\eden_003.wav           0.436774\n",
       "2    eden  data\\eden_001.wav  data\\eden_004.wav           0.558711\n",
       "3    eden  data\\eden_001.wav  data\\eden_005.wav           0.604544\n",
       "4    eden  data\\eden_001.wav  data\\eden_006.wav           0.587780"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute pairwise cosine similarity for embeddings of the SAME speaker\n",
    "df = df_emb.copy()\n",
    "# df[\"embedding_vector\"] = df[\"embedding_vector\"].apply(json.loads)\n",
    "# df[\"embedding_vector\"] = df[\"embedding_vector\"].apply(ast.literal_eval)\n",
    "\n",
    "speakers = sorted(df[\"true_label\"].unique())\n",
    "similarity_rows = []\n",
    "\n",
    "for spk in speakers:\n",
    "    df_spk = df[df[\"true_label\"] == spk]\n",
    "\n",
    "    for i, j in itertools.combinations(df_spk.index, 2):\n",
    "        emb_i = torch.tensor(df_spk.loc[i, \"embedding_vector\"])\n",
    "        emb_j = torch.tensor(df_spk.loc[j, \"embedding_vector\"])\n",
    "\n",
    "        sim = F.cosine_similarity(emb_i, emb_j, dim=0).item()\n",
    "\n",
    "        similarity_rows.append({\n",
    "            \"speaker\": spk,\n",
    "            \"wav1\": df_spk.loc[i, \"path\"],\n",
    "            \"wav2\": df_spk.loc[j, \"path\"],\n",
    "            \"cosine_similarity\": sim\n",
    "        })\n",
    "\n",
    "df_sim = pd.DataFrame(similarity_rows)\n",
    "df_sim.to_csv(\"user_similarity_pairs.csv\", index=False)\n",
    "\n",
    "\n",
    "df_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2209504e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>template_path</th>\n",
       "      <th>average_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eden</td>\n",
       "      <td>data\\eden_013.wav</td>\n",
       "      <td>0.610160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>idan</td>\n",
       "      <td>data\\idan_012.wav</td>\n",
       "      <td>0.698508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yoav</td>\n",
       "      <td>data\\yoav_022.wav</td>\n",
       "      <td>0.653120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  speaker      template_path  average_similarity\n",
       "0    eden  data\\eden_013.wav            0.610160\n",
       "1    idan  data\\idan_012.wav            0.698508\n",
       "2    yoav  data\\yoav_022.wav            0.653120"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compute average similarity per file\n",
    "\n",
    "template_rows = []\n",
    "\n",
    "\n",
    "for spk in speakers:\n",
    "    df_spk = df[df[\"true_label\"] == spk]\n",
    "\n",
    "    avg_scores = []\n",
    "\n",
    "    for idx in df_spk.index:\n",
    "        file_path = df_spk.loc[idx, \"path\"]\n",
    "\n",
    "        # Get all rows where this file appears in similarity table\n",
    "        rel1 = df_sim[(df_sim[\"speaker\"] == spk) & (df_sim[\"wav1\"] == file_path)]\n",
    "        rel2 = df_sim[(df_sim[\"speaker\"] == spk) & (df_sim[\"wav2\"] == file_path)]\n",
    "\n",
    "        sims = list(rel1[\"cosine_similarity\"]) + list(rel2[\"cosine_similarity\"])\n",
    "\n",
    "        if len(sims) == 0:\n",
    "            avg_sim = 0.0\n",
    "        else:\n",
    "            avg_sim = sum(sims) / len(sims)\n",
    "\n",
    "        avg_scores.append((file_path, avg_sim))\n",
    "\n",
    "    # pick file with best similarity\n",
    "    best_file, best_score = sorted(avg_scores, key=lambda x: x[1], reverse=True)[0]\n",
    "\n",
    "    template_rows.append({\n",
    "        \"speaker\": spk,\n",
    "        \"template_path\": best_file,\n",
    "        \"average_similarity\": best_score\n",
    "    })\n",
    "\n",
    "df_templates = pd.DataFrame(template_rows)\n",
    "df_templates.to_csv(\"user_best_templates.csv\", index=False)\n",
    "\n",
    "\n",
    "df_templates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e126a033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eden': tensor([ 0.1227, -0.0100,  0.0723,  0.0259,  0.0044,  0.0512, -0.0072,  0.0143,\n",
       "          0.0322, -0.0428,  0.0601, -0.0291,  0.0654,  0.0840, -0.0368, -0.0069,\n",
       "          0.0712,  0.1527, -0.1150,  0.1289, -0.0439, -0.1348,  0.0709, -0.0237,\n",
       "         -0.0191, -0.0747,  0.1285,  0.0732, -0.0189, -0.1513,  0.0539, -0.1086,\n",
       "          0.0813, -0.0434,  0.0332, -0.1620, -0.0673, -0.0817, -0.0422, -0.0610,\n",
       "         -0.0061,  0.0252, -0.1141, -0.0594,  0.0839, -0.1235,  0.0266, -0.1059,\n",
       "          0.1042, -0.0180, -0.0267, -0.0257, -0.0073,  0.0246, -0.0499, -0.0948,\n",
       "         -0.0570, -0.0782, -0.0806,  0.0729, -0.0061,  0.0275, -0.0348,  0.1019,\n",
       "          0.0543, -0.1483, -0.0114,  0.0424, -0.0461, -0.0859,  0.0203,  0.0665,\n",
       "          0.0808, -0.0109,  0.0240,  0.0030,  0.0432, -0.1256, -0.0168,  0.0117,\n",
       "          0.0896,  0.0822, -0.0198, -0.1135,  0.0634,  0.0273, -0.0469,  0.1008,\n",
       "         -0.0963, -0.0890,  0.0446,  0.0438, -0.0259,  0.1812, -0.1122, -0.0120,\n",
       "         -0.0004,  0.1757, -0.1585,  0.0456,  0.0653,  0.0508, -0.0872, -0.0594,\n",
       "          0.0332,  0.0312, -0.1076, -0.0955, -0.0007, -0.0313, -0.0678, -0.1331,\n",
       "          0.0122,  0.0812, -0.1075, -0.0137,  0.0409,  0.1741,  0.0682, -0.0658,\n",
       "         -0.0135, -0.0394, -0.0534, -0.0108, -0.0085,  0.0153,  0.0949, -0.0459,\n",
       "          0.0315,  0.1844, -0.0414, -0.0689,  0.0105, -0.0536, -0.0465, -0.0843,\n",
       "         -0.0487,  0.0285,  0.0434, -0.0809,  0.0116, -0.1281, -0.0936, -0.0016,\n",
       "          0.0438,  0.1082, -0.0469,  0.0198, -0.0750,  0.0163, -0.0197,  0.0025,\n",
       "          0.0650,  0.0622, -0.0045,  0.1029, -0.0510,  0.0323, -0.0035, -0.0096,\n",
       "         -0.0117,  0.1787,  0.0180, -0.1335,  0.0306, -0.0608, -0.0396, -0.0395,\n",
       "          0.0248, -0.0438,  0.0542, -0.0145, -0.0383,  0.0098, -0.0494, -0.0985,\n",
       "          0.0348, -0.0829, -0.0380, -0.0507, -0.0334,  0.0496, -0.0749,  0.0316,\n",
       "          0.0008,  0.1557, -0.0287,  0.0174,  0.0128, -0.0599,  0.0139, -0.0541]),\n",
       " 'idan': tensor([ 3.6617e-02,  4.3111e-02,  3.3060e-02,  7.0561e-02,  2.8326e-02,\n",
       "         -1.1716e-01,  2.7265e-02, -6.9114e-02, -1.0449e-01,  4.9787e-02,\n",
       "          3.5423e-02,  1.4675e-01,  1.9864e-02,  1.5169e-03, -1.9436e-02,\n",
       "          1.3124e-01, -1.6048e-02,  1.4789e-02,  1.1426e-02,  1.1211e-01,\n",
       "          1.3717e-01,  1.8227e-02,  5.0889e-02,  1.9032e-02, -1.3242e-02,\n",
       "          1.8261e-02,  9.8694e-02,  4.3842e-03,  1.4547e-01, -2.6026e-02,\n",
       "          1.4148e-03, -7.7178e-02,  7.4130e-02, -2.8031e-02,  4.8410e-02,\n",
       "         -1.0830e-01, -8.3768e-02,  4.4070e-02,  3.7746e-02, -3.3799e-02,\n",
       "         -1.1191e-02,  1.9679e-01, -1.3407e-01, -1.1752e-01, -3.4837e-02,\n",
       "         -1.4735e-01, -1.1079e-03, -5.2294e-02, -7.7535e-02, -3.7059e-02,\n",
       "         -3.8895e-02,  5.8909e-03, -1.9567e-02,  1.1656e-01, -5.0647e-02,\n",
       "          1.0129e-02, -1.9363e-02, -4.7208e-02,  2.0148e-03,  2.4904e-02,\n",
       "          2.0206e-02, -2.6781e-02, -7.3132e-02,  2.6603e-03,  1.0909e-04,\n",
       "          8.9296e-02,  9.8069e-02,  8.1041e-02,  2.2820e-02,  6.8770e-02,\n",
       "         -1.4535e-01, -5.4959e-02, -2.1174e-02,  2.4215e-02, -4.8499e-03,\n",
       "         -7.6348e-02, -7.0421e-03, -7.5453e-02,  7.9600e-02,  3.4253e-02,\n",
       "         -7.5243e-02,  4.6556e-02,  4.6798e-02, -7.3430e-02,  1.7330e-01,\n",
       "          6.4769e-02, -8.4042e-02,  1.8679e-02, -1.3293e-01,  1.5272e-03,\n",
       "          2.6267e-02,  1.6712e-02, -3.7886e-02, -1.2285e-01, -7.4915e-02,\n",
       "          1.8410e-02,  1.2275e-01, -4.2389e-02, -5.0600e-02, -5.6136e-02,\n",
       "          1.8481e-02, -1.0521e-01, -2.7154e-02, -3.1997e-02,  6.3972e-02,\n",
       "         -1.3714e-02, -1.4803e-02,  2.6021e-02,  1.0527e-01,  1.5398e-01,\n",
       "         -2.5514e-02,  8.2011e-02, -1.7371e-03,  8.9790e-02, -7.3285e-02,\n",
       "         -4.2876e-02,  1.0925e-01,  6.8397e-02, -8.3701e-02,  5.2680e-02,\n",
       "         -5.6741e-02, -1.0583e-01,  5.9335e-04,  4.5202e-02,  6.0598e-02,\n",
       "          3.2496e-03,  1.1160e-01, -2.2785e-02, -1.1989e-01, -1.6935e-01,\n",
       "         -8.9150e-02,  6.1384e-03, -4.1363e-02, -2.8739e-02, -6.5315e-03,\n",
       "         -9.9340e-02,  8.8951e-02,  7.5092e-02, -5.9023e-02,  3.0679e-02,\n",
       "         -1.7441e-02, -1.0430e-01, -1.7867e-01,  4.2360e-02,  5.7512e-02,\n",
       "         -7.4465e-02,  2.2729e-02,  4.5618e-02, -3.9378e-02,  7.8763e-02,\n",
       "         -8.0727e-02,  7.2681e-02, -9.6793e-02,  4.9901e-02, -1.6023e-02,\n",
       "          1.0047e-01,  3.8750e-04, -3.0534e-02, -9.2913e-03,  1.4717e-02,\n",
       "          5.4079e-02,  7.4969e-02,  1.3333e-01, -1.0905e-02,  8.1686e-02,\n",
       "         -5.2419e-04, -1.0181e-01, -1.4442e-02, -7.8170e-02, -6.5821e-02,\n",
       "          1.0512e-01, -7.5629e-03, -1.0304e-01,  5.2984e-02,  4.9561e-02,\n",
       "         -1.3346e-01,  1.1956e-01, -4.7104e-02, -3.6765e-02, -8.4545e-02,\n",
       "         -8.4350e-02,  1.1309e-03, -2.9207e-02,  1.0572e-01,  2.7631e-02,\n",
       "          1.2136e-01, -3.5622e-02,  4.3608e-02, -8.5789e-03, -8.3340e-02,\n",
       "          1.6238e-02,  9.8150e-03]),\n",
       " 'yoav': tensor([ 1.0544e-01, -2.2727e-02, -7.1862e-02, -1.9995e-02, -1.5180e-01,\n",
       "          4.3301e-02, -4.0799e-02,  8.8061e-05, -1.1595e-02,  1.6167e-01,\n",
       "          6.3420e-03,  2.8001e-03, -1.4834e-01, -6.5504e-02,  1.0443e-01,\n",
       "          3.1525e-02, -9.8566e-02, -2.8445e-02,  2.1877e-02,  3.3583e-02,\n",
       "          7.2328e-02, -1.6775e-01,  1.1899e-01,  3.0467e-03, -1.2228e-01,\n",
       "          3.9689e-02, -1.0007e-01,  1.0353e-01,  2.5880e-02,  1.9103e-02,\n",
       "          2.5525e-02,  4.2434e-02, -5.3050e-02, -1.9946e-02, -1.3379e-01,\n",
       "         -4.1216e-02,  4.0234e-03,  2.2779e-02, -3.9897e-02,  1.9330e-02,\n",
       "         -2.2330e-02,  1.4225e-02,  4.6649e-02, -5.3942e-02, -9.0624e-02,\n",
       "         -2.2106e-02,  5.0595e-02,  6.8197e-02, -2.4471e-02, -1.9606e-02,\n",
       "         -1.2217e-02,  8.1509e-02,  5.4996e-03, -2.7430e-02,  5.1653e-02,\n",
       "         -5.1857e-02, -9.3121e-02, -4.5579e-02, -7.6246e-02,  2.2652e-02,\n",
       "         -1.0555e-01, -8.7049e-03, -1.0428e-01,  5.0351e-02, -3.1068e-02,\n",
       "          6.5948e-02, -9.1789e-02,  9.7383e-02,  1.6796e-01, -5.4789e-02,\n",
       "         -1.4754e-01, -1.1217e-01, -1.4281e-02, -5.4117e-02, -8.8889e-02,\n",
       "         -4.8046e-02, -5.1353e-02,  1.9463e-02,  1.2301e-01, -2.3251e-02,\n",
       "          8.9606e-02, -7.3901e-02,  7.5339e-02, -1.2285e-01,  1.3112e-01,\n",
       "         -1.7921e-04,  6.9912e-03,  1.7549e-01, -6.0775e-03, -1.1327e-02,\n",
       "          4.7002e-04,  6.8737e-03, -1.0208e-01, -4.0756e-02, -4.5998e-02,\n",
       "          1.4766e-01, -1.2061e-02,  3.1627e-02, -1.1150e-01,  1.0934e-01,\n",
       "          7.9825e-02,  1.1211e-02, -9.6927e-02,  4.8191e-02,  1.2231e-01,\n",
       "          2.2066e-02,  1.3344e-01, -5.0702e-02, -1.0251e-01,  8.5832e-02,\n",
       "          7.5079e-02, -2.7257e-02, -4.9260e-02,  1.1943e-01,  6.5462e-02,\n",
       "          4.1300e-02, -7.2804e-02,  6.4509e-02,  3.0474e-02,  1.5384e-02,\n",
       "         -3.2879e-02,  6.3107e-02, -6.3038e-02, -3.2196e-02,  1.1449e-01,\n",
       "          3.0264e-02,  5.3851e-02,  3.8384e-02,  9.1364e-02,  4.7666e-03,\n",
       "         -2.7188e-02, -1.9252e-03,  7.7272e-02,  2.1612e-02,  1.1804e-02,\n",
       "          2.9006e-02, -1.4384e-02,  1.3327e-02,  1.6797e-01, -5.6578e-02,\n",
       "         -3.0394e-02, -2.9377e-02,  4.6242e-02,  9.2049e-02,  2.9397e-02,\n",
       "          2.0764e-02, -9.3422e-02, -5.3670e-02, -5.9029e-02, -8.8324e-02,\n",
       "         -3.5139e-02, -3.7444e-03, -1.0813e-01,  8.9459e-02,  6.6322e-02,\n",
       "         -7.3260e-02,  1.0114e-01, -7.8607e-02, -6.6381e-03,  3.1301e-02,\n",
       "         -2.0347e-02, -8.7088e-02, -1.0216e-01, -1.1839e-02,  1.1611e-01,\n",
       "         -5.1694e-02,  1.2783e-03, -1.0364e-01,  7.0591e-02,  5.1529e-02,\n",
       "          8.6413e-02,  4.6996e-03, -9.1188e-02,  1.0810e-02, -5.1053e-02,\n",
       "          2.5711e-03, -1.2648e-01,  9.6753e-02,  6.1344e-02,  3.9416e-02,\n",
       "          4.5433e-02, -1.8058e-01,  2.9010e-02, -1.2879e-02, -2.4880e-02,\n",
       "         -3.3185e-02,  2.9866e-02,  4.5384e-02,  4.0684e-03,  2.9659e-03,\n",
       "         -7.4171e-02,  4.9661e-02])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the best file as the template for each speaker\n",
    "\n",
    "\n",
    "template_embeddings = {}\n",
    "\n",
    "for _, row in df_templates.iterrows():\n",
    "    spk = row[\"speaker\"]\n",
    "    template_file = row[\"template_path\"]\n",
    "    \n",
    "    template_embeddings[spk] = torch.tensor(\n",
    "        df[df[\"path\"] == template_file][\"embedding_vector\"].values[0]\n",
    "    )\n",
    "\n",
    "template_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a798de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoav1\\AppData\\Local\\Temp\\ipykernel_38848\\1493466862.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  emb = torch.tensor(emb_dict[wav_key])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>true_label</th>\n",
       "      <th>prob_eden</th>\n",
       "      <th>prob_idan</th>\n",
       "      <th>prob_yoav</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data\\eden_001.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>0.992331</td>\n",
       "      <td>0.005956</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>eden</td>\n",
       "      <td>0.992331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data\\eden_002.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>0.918550</td>\n",
       "      <td>0.064232</td>\n",
       "      <td>0.017218</td>\n",
       "      <td>eden</td>\n",
       "      <td>0.918550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data\\eden_003.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>0.954194</td>\n",
       "      <td>0.037506</td>\n",
       "      <td>0.008299</td>\n",
       "      <td>eden</td>\n",
       "      <td>0.954194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data\\eden_004.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>0.983065</td>\n",
       "      <td>0.015297</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>eden</td>\n",
       "      <td>0.983065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data\\eden_005.wav</td>\n",
       "      <td>eden</td>\n",
       "      <td>0.965382</td>\n",
       "      <td>0.032417</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>eden</td>\n",
       "      <td>0.965382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                path true_label  prob_eden  prob_idan  prob_yoav  \\\n",
       "0  data\\eden_001.wav       eden   0.992331   0.005956   0.001713   \n",
       "1  data\\eden_002.wav       eden   0.918550   0.064232   0.017218   \n",
       "2  data\\eden_003.wav       eden   0.954194   0.037506   0.008299   \n",
       "3  data\\eden_004.wav       eden   0.983065   0.015297   0.001638   \n",
       "4  data\\eden_005.wav       eden   0.965382   0.032417   0.002201   \n",
       "\n",
       "  predicted_label  predicted_probability  \n",
       "0            eden               0.992331  \n",
       "1            eden               0.918550  \n",
       "2            eden               0.954194  \n",
       "3            eden               0.983065  \n",
       "4            eden               0.965382  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine(test_embedding, template_spk)\n",
    "# softmax → probabilities\n",
    "\n",
    "temperature = 0.1\n",
    "final_rows = []\n",
    "\n",
    "\n",
    "for wav in wav_paths:\n",
    "\n",
    "    wav_key = str(wav)\n",
    "\n",
    "\n",
    "    # retrieve embedding\n",
    "    emb = torch.tensor(emb_dict[wav_key])\n",
    "    true_label = wav.stem.split(\"_\")[0]\n",
    "\n",
    "    sims = []\n",
    "    for spk in speakers:\n",
    "        sim = F.cosine_similarity(emb, template_embeddings[spk], dim=0).item()\n",
    "        sims.append(sim)\n",
    "\n",
    "    sims_tensor = torch.tensor(sims)\n",
    "    probs = F.softmax(sims_tensor / temperature, dim=0)\n",
    "\n",
    "    row = {\n",
    "        \"path\": wav_key,   \n",
    "        \"true_label\": true_label,\n",
    "    }\n",
    "\n",
    "    # probability columns\n",
    "    for i, spk in enumerate(speakers):\n",
    "        row[f\"prob_{spk}\"] = probs[i].item()\n",
    "\n",
    "    # predicted speaker\n",
    "    best_idx = torch.argmax(probs).item()\n",
    "    row[\"predicted_label\"] = speakers[best_idx]\n",
    "    row[\"predicted_probability\"] = probs[best_idx].item()\n",
    "\n",
    "    final_rows.append(row)\n",
    "\n",
    "df_final = pd.DataFrame(final_rows)\n",
    "df_final.to_csv(\"user_final_predictions.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96560cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (90, 192)\n",
      "Num samples: 90\n",
      "Unique speakers: ['eden' 'idan' 'yoav']\n"
     ]
    }
   ],
   "source": [
    "df = df_emb.copy()\n",
    "\n",
    "labels = df[\"true_label\"].values\n",
    "\n",
    "emb_list = df[\"embedding_vector\"].tolist()\n",
    "\n",
    "embeddings = np.asarray(emb_list, dtype=np.float32)\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "print(\"Num samples:\", len(labels))\n",
    "print(\"Unique speakers:\", np.unique(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cosine_similarity_matrix(X: np.ndarray) -> np.ndarray:\n",
    "    X_norm = X / np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    return X_norm @ X_norm.T\n",
    "\n",
    "def compute_eer_from_embeddings(embeddings: np.ndarray, labels: np.ndarray):\n",
    "    sim_mat = cosine_similarity_matrix(embeddings)\n",
    "    N = len(labels)\n",
    "\n",
    "    scores = []\n",
    "    gt = []\n",
    "\n",
    "    # Build pairwise labels\n",
    "    for i in range(N):\n",
    "        for j in range(i + 1, N):\n",
    "            scores.append(sim_mat[i, j])\n",
    "            gt.append(1 if labels[i] == labels[j] else 0)\n",
    "\n",
    "    scores = np.array(scores)\n",
    "    gt = np.array(gt)\n",
    "\n",
    "    # ROC curve\n",
    "    fpr, tpr, thresh = roc_curve(gt, scores)\n",
    "    fnr = 1 - tpr\n",
    "\n",
    "    # Find EER\n",
    "    idx = np.argmin(np.abs(fnr - fpr))\n",
    "    eer = (fnr[idx] + fpr[idx]) / 2\n",
    "    thr_eer = thresh[idx]\n",
    "\n",
    "    return eer, thr_eer, fpr, fnr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e85d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER = 0.45%\n",
      "Threshold at EER (cosine similarity): 0.3629\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eer, thr_eer, fpr, fnr = compute_eer_from_embeddings(embeddings, labels)\n",
    "\n",
    "print(f\"EER = {eer * 100:.2f}%\")\n",
    "print(f\"Threshold at EER (cosine similarity): {thr_eer:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
