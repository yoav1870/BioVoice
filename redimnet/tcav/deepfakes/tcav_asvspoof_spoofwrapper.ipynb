{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c3a4c25",
   "metadata": {},
   "source": [
    "# TCAV on ASVspoof 2019 (LA) — ReDimNet + Logistic Probe (Spoof vs Bonafide)\n",
    "\n",
    "This notebook runs **TCAV** to explain a **spoof (fake) vs bonafide (real)** decision.\n",
    "\n",
    "Pipeline:\n",
    "- Waveform (HF dataset) → `ReDimNet.spec` → mel\n",
    "- mel → ReDimNet backbone/pool/bn/linear → embedding\n",
    "- embedding → StandardScaler → LogisticRegression probe → 2-class logits `[real, fake]`\n",
    "- TCAV computes concept influence on **target class = Fake**.\n",
    "\n",
    "Expected paths:\n",
    "- Concepts: `/home/SpeakerRec/BioVoice/concept/temp_concepts/<concept_name>/*.npy`\n",
    "- TCAV subset: `/home/SpeakerRec/BioVoice/data/datasets/asv_spoof_2019/tcav__20_speakers_10_real_10_fake`\n",
    "- Probe model: `/home/SpeakerRec/BioVoice/data/models/asvspoof_probe_50_50/{scaler.pkl, logistic_regression.pkl}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e642b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SpeakerRec/BioVoice/.venv_asv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.1.2+cu121\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_from_disk\n",
    "from captum.concept import TCAV, Concept\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e009ac7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT = /home/SpeakerRec/BioVoice\n",
      "DEVICE = cpu\n",
      "OUT_DIR = /home/SpeakerRec/BioVoice/output\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# -------- Paths / device --------\n",
    "PROJECT_ROOT = Path(\"/home/SpeakerRec/BioVoice\")\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # TCAV on CPU\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
    "print(\"DEVICE =\", DEVICE)\n",
    "\n",
    "CONCEPT_ROOT = PROJECT_ROOT / \"concept\" / \"temp_concepts\"\n",
    "assert CONCEPT_ROOT.exists(), f\"Missing {CONCEPT_ROOT}\"\n",
    "\n",
    "TCAV_DATASET_PATH = PROJECT_ROOT / \"data\" / \"datasets\" / \"asv_spoof_2019\" / \"tcav__20_speakers_10_real_10_fake\"\n",
    "assert TCAV_DATASET_PATH.exists(), f\"Missing {TCAV_DATASET_PATH}\"\n",
    "\n",
    "MODEL_DIR = PROJECT_ROOT / \"data\" / \"models\" / \"asvspoof_probe_50_50\"\n",
    "LOGREG_PATH = MODEL_DIR / \"logistic_regression.pkl\"\n",
    "SCALER_PATH = MODEL_DIR / \"scaler.pkl\"\n",
    "assert LOGREG_PATH.exists(), f\"Missing {LOGREG_PATH}\"\n",
    "assert SCALER_PATH.exists(), f\"Missing {SCALER_PATH}\"\n",
    "\n",
    "OUT_DIR = PROJECT_ROOT / \"data\" / \"tcav\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"OUT_DIR =\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90ac1b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tcav_subset: 1150\n",
      "Columns: ['speaker_id', 'audio_file_name', 'audio', 'system_id', 'key']\n",
      "key counts: {0: 670, 1: 480}\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# -------- Load TCAV subset (HF dataset) --------\n",
    "tcav_subset = load_from_disk(TCAV_DATASET_PATH)\n",
    "print(\"Loaded tcav_subset:\", len(tcav_subset))\n",
    "print(\"Columns:\", tcav_subset.column_names)\n",
    "\n",
    "# ASVspoof: key==1 bonafide(real), key==0 spoof(fake)\n",
    "print(\"key counts:\", pd.Series(tcav_subset[\"key\"]).value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9e58578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/SpeakerRec/.cache/torch/hub/IDRnD_ReDimNet_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ReDimNet. N_MELS = 72\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# -------- Load ReDimNet --------\n",
    "redim_model = (\n",
    "    torch.hub.load(\n",
    "        \"IDRnD/ReDimNet\",\n",
    "        \"ReDimNet\",\n",
    "        model_name=\"b5\",\n",
    "        train_type=\"ptn\",\n",
    "        dataset=\"vox2\",\n",
    "    )\n",
    "    .to(DEVICE)\n",
    "    .eval()\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    dummy_wav = torch.zeros(1, 16000, device=DEVICE)\n",
    "    dummy_mel = redim_model.spec(dummy_wav)  # (1, N_MELS, T)\n",
    "\n",
    "N_MELS = int(dummy_mel.shape[1])\n",
    "print(\"Loaded ReDimNet. N_MELS =\", N_MELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e3c2a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded probe: <class 'sklearn.linear_model._logistic.LogisticRegression'> <class 'sklearn.preprocessing._data.StandardScaler'>\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# -------- Load scaler + logistic probe --------\n",
    "with open(LOGREG_PATH, \"rb\") as f:\n",
    "    logreg_clf = pickle.load(f)\n",
    "\n",
    "with open(SCALER_PATH, \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "print(\"Loaded probe:\", type(logreg_clf), type(scaler))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ef78bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ReDimNetSpoofWrapper model.\n"
     ]
    }
   ],
   "source": [
    "class ReDimNetSpoofWrapper(nn.Module):\n",
    "    def __init__(self, redim_model, W, b, mean, scale, l2_norm_emb=True):\n",
    "        super().__init__()\n",
    "        self.redim = redim_model\n",
    "        self.l2_norm_emb = l2_norm_emb\n",
    "\n",
    "        D = W.shape[1]\n",
    "\n",
    "        # scaler parameters as buffers\n",
    "        self.register_buffer(\"mean\", torch.tensor(mean, dtype=torch.float32))\n",
    "        self.register_buffer(\"scale\", torch.tensor(scale, dtype=torch.float32))\n",
    "\n",
    "        # logistic as linear layer\n",
    "        self.linear = nn.Linear(D, 1)\n",
    "        self.linear.weight.data = torch.tensor(W, dtype=torch.float32)\n",
    "        self.linear.bias.data = torch.tensor(b, dtype=torch.float32)\n",
    "\n",
    "    def forward(self, mel4d):\n",
    "        x = self.redim.backbone(mel4d)\n",
    "        x = self.redim.pool(x)\n",
    "        x = self.redim.bn(x)\n",
    "        emb = self.redim.linear(x)\n",
    "\n",
    "        if self.l2_norm_emb:\n",
    "            emb = emb / (emb.norm(p=2, dim=1, keepdim=True) + 1e-12)\n",
    "\n",
    "        # torch scaling\n",
    "        emb = (emb - self.mean) / self.scale\n",
    "\n",
    "        score = self.linear(emb)  # [B,1]\n",
    "\n",
    "        logits = torch.cat([-score, score], dim=1)  # [B,2]\n",
    "\n",
    "        return logits\n",
    "\n",
    "spoof_model = (\n",
    "    ReDimNetSpoofWrapper(\n",
    "        redim_model,\n",
    "        W=logreg_clf.coef_,\n",
    "        b=logreg_clf.intercept_,\n",
    "        mean=scaler.mean_,\n",
    "        scale=scaler.scale_,\n",
    "    )\n",
    "    .to(DEVICE)\n",
    "    .eval()\n",
    ")\n",
    "print(\"Created ReDimNetSpoofWrapper model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee6950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Pick 1 layer for speed (add stage5 later if you want)\n",
    "TARGET_LAYERS = {\n",
    "    \"stage4\": spoof_model.redim.backbone.stage4[2],\n",
    "    # \"stage5\": spoof_model.redim.backbone.stage5[2],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fdd0950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def module_name_in_model(model: torch.nn.Module, target_module: torch.nn.Module) -> str:\n",
    "    for name, mod in model.named_modules():\n",
    "        if mod is target_module:\n",
    "            return name\n",
    "    raise RuntimeError(\"Could not find selected layer module in model.named_modules()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "471dd362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def fix_mel_frames(mel_3d: torch.Tensor, target_frames: int) -> torch.Tensor:\n",
    "    \"\"\"mel_3d: (1, N_MELS, T) -> (1, N_MELS, target_frames)\"\"\"\n",
    "    T = int(mel_3d.shape[-1])\n",
    "    if T == target_frames:\n",
    "        return mel_3d\n",
    "    if T > target_frames:\n",
    "        start = (T - target_frames) // 2\n",
    "        return mel_3d[..., start:start + target_frames]\n",
    "    pad = target_frames - T\n",
    "    return F.pad(mel_3d, (0, pad), mode=\"constant\", value=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce1beed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts: ['long_constant_thick', 'long_constant_thick_Vibrato', 'long_dropping_flat_thick', 'long_dropping_flat_thick_Vibrato', 'long_dropping_steep_thick', 'long_dropping_steep_thin', 'long_rising_flat_thick', 'long_rising_steep_thick', 'long_rising_steep_thin', 'short_constant_thick', 'short_dropping_steep_thick', 'short_dropping_steep_thin', 'short_rising_steep_thick', 'short_rising_steep_thin']\n",
      "TARGET_FRAMES = 304\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "def infer_frames_for_random(concept_dirs: list[Path]) -> int:\n",
    "    for d in concept_dirs:\n",
    "        f = next(d.glob(\"*.npy\"), None)\n",
    "        if f is not None:\n",
    "            mel = np.load(f)\n",
    "            return int(mel.shape[1])\n",
    "    raise RuntimeError(\"Could not infer frames from concept dirs\")\n",
    "\n",
    "concept_dirs = sorted([d for d in CONCEPT_ROOT.iterdir() if d.is_dir()])\n",
    "if not concept_dirs:\n",
    "    raise RuntimeError(f\"No concept folders in {CONCEPT_ROOT}\")\n",
    "\n",
    "concept_names = [d.name for d in concept_dirs]\n",
    "TARGET_FRAMES = infer_frames_for_random(concept_dirs)\n",
    "\n",
    "print(\"Concepts:\", concept_names)\n",
    "print(\"TARGET_FRAMES =\", TARGET_FRAMES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e80ff41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 14 concepts + random.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "CONCEPT_SAMPLES = 100\n",
    "RANDOM_SAMPLES = 100\n",
    "BATCH_SIZE_CONCEPT = 1\n",
    "FORCE_TRAIN_CAVS = True\n",
    "\n",
    "class ConceptNPYDataset(Dataset):\n",
    "    def __init__(self, concept_dir: Path, limit: int | None = None):\n",
    "        self.files = sorted(concept_dir.glob(\"*.npy\"))\n",
    "        if not self.files:\n",
    "            raise RuntimeError(f\"No .npy found in {concept_dir}\")\n",
    "        if limit is not None:\n",
    "            self.files = self.files[:limit]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mel = np.load(self.files[idx]).astype(np.float32)  # (N_MELS, T)\n",
    "        if mel.shape[0] != N_MELS:\n",
    "            raise RuntimeError(f\"{self.files[idx].name}: expected {N_MELS} bins, got {mel.shape}\")\n",
    "        x = torch.from_numpy(mel).unsqueeze(0)  # (1, N_MELS, T)\n",
    "        x = fix_mel_frames(x, TARGET_FRAMES)    # (1, N_MELS, TARGET_FRAMES)\n",
    "        return x\n",
    "\n",
    "class RandomMelDataset(Dataset):\n",
    "    def __init__(self, n_samples: int, frames: int):\n",
    "        self.n_samples = n_samples\n",
    "        self.frames = frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.randn(1, N_MELS, self.frames, dtype=torch.float32)\n",
    "\n",
    "positive_concepts = []\n",
    "for idx, cdir in enumerate(concept_dirs):\n",
    "    ds = ConceptNPYDataset(cdir, limit=CONCEPT_SAMPLES)\n",
    "    dl = DataLoader(ds, batch_size=BATCH_SIZE_CONCEPT, shuffle=False, num_workers=0)\n",
    "    positive_concepts.append(Concept(id=idx, name=cdir.name, data_iter=dl))\n",
    "\n",
    "rand_ds = RandomMelDataset(n_samples=RANDOM_SAMPLES, frames=TARGET_FRAMES)\n",
    "rand_dl = DataLoader(rand_ds, batch_size=BATCH_SIZE_CONCEPT, shuffle=False, num_workers=0)\n",
    "random_concept = Concept(id=len(positive_concepts), name=\"random\", data_iter=rand_dl)\n",
    "\n",
    "experimental_sets = [[c, random_concept] for c in positive_concepts]\n",
    "\n",
    "print(\"Prepared\", len(positive_concepts), \"concepts + random.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e822d512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: stage4 -> redim.backbone.stage4.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SpeakerRec/BioVoice/.venv_asv/lib/python3.10/site-packages/captum/concept/_utils/classifier.py:130: UserWarning: Using default classifier for TCAV which keeps input both train and test datasets in the memory. Consider defining your own classifier that doesn't rely heavily on memory, for large number of concepts, by extending `Classifer` abstract class\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Initialize TCAV per layer\n",
    "all_tcav = {}\n",
    "for layer_key, layer_module in TARGET_LAYERS.items():\n",
    "    layer_name = module_name_in_model(spoof_model, layer_module)\n",
    "    print(\"Layer:\", layer_key, \"->\", layer_name)\n",
    "    all_tcav[layer_key] = TCAV(spoof_model, [layer_name], test_split_ratio=0.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a75d4ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing CAV accuracies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SpeakerRec/BioVoice/.venv_asv/lib/python3.10/site-packages/captum/_utils/models/linear_model/train.py:350: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  bias_values = torch.FloatTensor([sklearn_model.intercept_]).to(  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage4 rows: 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_key</th>\n",
       "      <th>concept name</th>\n",
       "      <th>layer name</th>\n",
       "      <th>cav acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stage4</td>\n",
       "      <td>long_constant_thick</td>\n",
       "      <td>redim.backbone.stage4.2</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stage4</td>\n",
       "      <td>long_constant_thick_Vibrato</td>\n",
       "      <td>redim.backbone.stage4.2</td>\n",
       "      <td>0.442308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stage4</td>\n",
       "      <td>long_dropping_flat_thick</td>\n",
       "      <td>redim.backbone.stage4.2</td>\n",
       "      <td>0.326923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stage4</td>\n",
       "      <td>long_dropping_flat_thick_Vibrato</td>\n",
       "      <td>redim.backbone.stage4.2</td>\n",
       "      <td>0.403846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stage4</td>\n",
       "      <td>long_dropping_steep_thick</td>\n",
       "      <td>redim.backbone.stage4.2</td>\n",
       "      <td>0.403846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stage4</td>\n",
       "      <td>long_dropping_steep_thin</td>\n",
       "      <td>redim.backbone.stage4.2</td>\n",
       "      <td>0.326923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stage4</td>\n",
       "      <td>long_rising_flat_thick</td>\n",
       "      <td>redim.backbone.stage4.2</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stage4</td>\n",
       "      <td>long_rising_steep_thick</td>\n",
       "      <td>redim.backbone.stage4.2</td>\n",
       "      <td>0.269231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stage4</td>\n",
       "      <td>long_rising_steep_thin</td>\n",
       "      <td>redim.backbone.stage4.2</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stage4</td>\n",
       "      <td>short_constant_thick</td>\n",
       "      <td>redim.backbone.stage4.2</td>\n",
       "      <td>0.269231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  layer_key                      concept name               layer name  \\\n",
       "0    stage4               long_constant_thick  redim.backbone.stage4.2   \n",
       "1    stage4       long_constant_thick_Vibrato  redim.backbone.stage4.2   \n",
       "2    stage4          long_dropping_flat_thick  redim.backbone.stage4.2   \n",
       "3    stage4  long_dropping_flat_thick_Vibrato  redim.backbone.stage4.2   \n",
       "4    stage4         long_dropping_steep_thick  redim.backbone.stage4.2   \n",
       "5    stage4          long_dropping_steep_thin  redim.backbone.stage4.2   \n",
       "6    stage4            long_rising_flat_thick  redim.backbone.stage4.2   \n",
       "7    stage4           long_rising_steep_thick  redim.backbone.stage4.2   \n",
       "8    stage4            long_rising_steep_thin  redim.backbone.stage4.2   \n",
       "9    stage4              short_constant_thick  redim.backbone.stage4.2   \n",
       "\n",
       "    cav acc  \n",
       "0  0.384615  \n",
       "1  0.442308  \n",
       "2  0.326923  \n",
       "3  0.403846  \n",
       "4  0.403846  \n",
       "5  0.326923  \n",
       "6  0.384615  \n",
       "7  0.269231  \n",
       "8  0.423077  \n",
       "9  0.269231  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "def compute_cav_acc_df(tcav: TCAV, positive_concepts: list[Concept], random_concept: Concept, layer_key: str) -> pd.DataFrame:\n",
    "    cavs_dict = tcav.compute_cavs([[c, random_concept] for c in positive_concepts], force_train=FORCE_TRAIN_CAVS)\n",
    "\n",
    "    rows = []\n",
    "    for concepts_key, layer_map in cavs_dict.items():\n",
    "        try:\n",
    "            pos_id = int(str(concepts_key).split(\"-\")[0])\n",
    "        except Exception:\n",
    "            continue\n",
    "        if not (0 <= pos_id < len(positive_concepts)):\n",
    "            continue\n",
    "        concept_name = positive_concepts[pos_id].name\n",
    "\n",
    "        for layer_name, cav_obj in layer_map.items():\n",
    "            if cav_obj is None or cav_obj.stats is None:\n",
    "                continue\n",
    "            acc = cav_obj.stats.get(\"accs\", None)\n",
    "            if acc is None:\n",
    "                acc = cav_obj.stats.get(\"acc\", None)\n",
    "            if isinstance(acc, torch.Tensor):\n",
    "                acc = acc.detach().cpu().item()\n",
    "            rows.append({\n",
    "                \"layer_key\": layer_key,\n",
    "                \"concept name\": concept_name,\n",
    "                \"layer name\": layer_name,\n",
    "                \"cav acc\": float(acc) if acc is not None else np.nan,\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "print(\"Computing CAV accuracies...\")\n",
    "acc_dfs = []\n",
    "for layer_key, tcav in all_tcav.items():\n",
    "    df_acc = compute_cav_acc_df(tcav, positive_concepts, random_concept, layer_key)\n",
    "    print(layer_key, \"rows:\", len(df_acc))\n",
    "    acc_dfs.append(df_acc)\n",
    "\n",
    "acc_df_combined = pd.concat(acc_dfs, ignore_index=True) if acc_dfs else pd.DataFrame()\n",
    "display(acc_df_combined.head(10) if not acc_df_combined.empty else acc_df_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a608bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def waveform_to_mel4d(audio_array: np.ndarray) -> torch.Tensor:\n",
    "    wav = torch.tensor(audio_array, dtype=torch.float32, device=DEVICE).unsqueeze(0)  # (1, T)\n",
    "    with torch.no_grad():\n",
    "        mel = redim_model.spec(wav)               # (1, N_MELS, Tm)\n",
    "    mel = fix_mel_frames(mel, TARGET_FRAMES)     # (1, N_MELS, TARGET_FRAMES)\n",
    "    mel4d = mel.unsqueeze(1)                     # (1, 1, N_MELS, TARGET_FRAMES)\n",
    "    return mel4d\n",
    "\n",
    "MAX_SAMPLES = None  # set e.g. 50 for a quick smoke test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b2cee78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running TCAV on samples: 1150\n",
      "df_tcav shape: (16100, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>system_id</th>\n",
       "      <th>key</th>\n",
       "      <th>true label</th>\n",
       "      <th>layer_key</th>\n",
       "      <th>concept name</th>\n",
       "      <th>layer name</th>\n",
       "      <th>positive percentage</th>\n",
       "      <th>magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LA_0039</td>\n",
       "      <td>A18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>stage4</td>\n",
       "      <td>long_constant_thick</td>\n",
       "      <td>redim.backbone.stage4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.386472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>LA_0039</td>\n",
       "      <td>A18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>stage4</td>\n",
       "      <td>long_constant_thick_Vibrato</td>\n",
       "      <td>redim.backbone.stage4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.665740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>LA_0039</td>\n",
       "      <td>A18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>stage4</td>\n",
       "      <td>long_dropping_flat_thick</td>\n",
       "      <td>redim.backbone.stage4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.124340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>LA_0039</td>\n",
       "      <td>A18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>stage4</td>\n",
       "      <td>long_dropping_flat_thick_Vibrato</td>\n",
       "      <td>redim.backbone.stage4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.578779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>LA_0039</td>\n",
       "      <td>A18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>stage4</td>\n",
       "      <td>long_dropping_steep_thick</td>\n",
       "      <td>redim.backbone.stage4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.497841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx speaker_id system_id  key  true label layer_key  \\\n",
       "0    0    LA_0039       A18    1           0    stage4   \n",
       "1    0    LA_0039       A18    1           0    stage4   \n",
       "2    0    LA_0039       A18    1           0    stage4   \n",
       "3    0    LA_0039       A18    1           0    stage4   \n",
       "4    0    LA_0039       A18    1           0    stage4   \n",
       "\n",
       "                       concept name               layer name  \\\n",
       "0               long_constant_thick  redim.backbone.stage4.2   \n",
       "1       long_constant_thick_Vibrato  redim.backbone.stage4.2   \n",
       "2          long_dropping_flat_thick  redim.backbone.stage4.2   \n",
       "3  long_dropping_flat_thick_Vibrato  redim.backbone.stage4.2   \n",
       "4         long_dropping_steep_thick  redim.backbone.stage4.2   \n",
       "\n",
       "   positive percentage  magnitude  \n",
       "0                  1.0   1.386472  \n",
       "1                  1.0   1.665740  \n",
       "2                  1.0   1.124340  \n",
       "3                  1.0   1.578779  \n",
       "4                  1.0   0.497841  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "rows = []\n",
    "TARGET_CLASS = 1  # Fake (spoof) class index in our wrapper logits\n",
    "\n",
    "n = len(tcav_subset) if MAX_SAMPLES is None else min(len(tcav_subset), MAX_SAMPLES)\n",
    "print(\"Running TCAV on samples:\", n)\n",
    "\n",
    "for i in range(n):\n",
    "    sample = tcav_subset[i]\n",
    "\n",
    "    audio_array = sample[\"audio\"][\"array\"]\n",
    "    speaker_id = sample.get(\"speaker_id\", None)\n",
    "    system_id = sample.get(\"system_id\", None)\n",
    "    key = int(sample[\"key\"])  # 1=real, 0=fake\n",
    "    true_label = 0 if key == 1 else 1\n",
    "\n",
    "    x = waveform_to_mel4d(audio_array)\n",
    "\n",
    "    for layer_key, tcav in all_tcav.items():\n",
    "        score_for_label = tcav.interpret(\n",
    "            inputs=x,\n",
    "            experimental_sets=experimental_sets,\n",
    "            target=TARGET_CLASS,\n",
    "        )\n",
    "\n",
    "        for exp_key, layer_dict in score_for_label.items():\n",
    "            try:\n",
    "                pos_idx = int(str(exp_key).split(\"-\")[0])\n",
    "            except Exception:\n",
    "                continue\n",
    "            if not (0 <= pos_idx < len(positive_concepts)):\n",
    "                continue\n",
    "\n",
    "            concept_name = positive_concepts[pos_idx].name\n",
    "\n",
    "            for layer_name, metrics in layer_dict.items():\n",
    "                sc = metrics.get(\"sign_count\")\n",
    "                mg = metrics.get(\"magnitude\")\n",
    "                if sc is None or mg is None:\n",
    "                    continue\n",
    "\n",
    "                sc = float(sc.detach().cpu().flatten()[0].item()) if isinstance(sc, torch.Tensor) else float(np.array(sc).flatten()[0])\n",
    "                mg = float(mg.detach().cpu().flatten()[0].item()) if isinstance(mg, torch.Tensor) else float(np.array(mg).flatten()[0])\n",
    "\n",
    "                rows.append({\n",
    "                    \"idx\": i,\n",
    "                    \"speaker_id\": speaker_id,\n",
    "                    \"system_id\": system_id,\n",
    "                    \"key\": key,\n",
    "                    \"true label\": true_label,\n",
    "                    \"layer_key\": layer_key,\n",
    "                    \"concept name\": concept_name,\n",
    "                    \"layer name\": layer_name,\n",
    "                    \"positive percentage\": sc,\n",
    "                    \"magnitude\": mg,\n",
    "                })\n",
    "\n",
    "df_tcav = pd.DataFrame(rows)\n",
    "print(\"df_tcav shape:\", df_tcav.shape)\n",
    "display(df_tcav.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1784a064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved -> /home/SpeakerRec/BioVoice/output/tcav_ASVspoof_stage4_spoofwrapper.csv\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "if not df_tcav.empty and not acc_df_combined.empty:\n",
    "    df_tcav = df_tcav.merge(acc_df_combined, on=[\"layer_key\", \"concept name\", \"layer name\"], how=\"left\")\n",
    "\n",
    "out_csv = OUT_DIR / \"tcav_ASVspoof_stage4_spoofwrapper.csv\"\n",
    "df_tcav.to_csv(out_csv, index=False)\n",
    "print(\"Saved ->\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91a07750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real (0) mean</th>\n",
       "      <th>Fake (1) mean</th>\n",
       "      <th>Fake-Real</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concept name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>short_rising_steep_thin</th>\n",
       "      <td>0.606250</td>\n",
       "      <td>0.619403</td>\n",
       "      <td>0.013153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_dropping_flat_thick_Vibrato</th>\n",
       "      <td>0.606250</td>\n",
       "      <td>0.605970</td>\n",
       "      <td>-0.000280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_constant_thick_Vibrato</th>\n",
       "      <td>0.664583</td>\n",
       "      <td>0.643284</td>\n",
       "      <td>-0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_rising_flat_thick</th>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.564179</td>\n",
       "      <td>-0.029571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_dropping_steep_thin</th>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.577612</td>\n",
       "      <td>-0.030721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_dropping_flat_thick</th>\n",
       "      <td>0.643750</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>-0.031810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_constant_thick</th>\n",
       "      <td>0.672917</td>\n",
       "      <td>0.635821</td>\n",
       "      <td>-0.037096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_dropping_steep_thick</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.617910</td>\n",
       "      <td>-0.038340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_dropping_steep_thick</th>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.555224</td>\n",
       "      <td>-0.038526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_constant_thick</th>\n",
       "      <td>0.639583</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.039583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_dropping_steep_thin</th>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.556716</td>\n",
       "      <td>-0.041200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_rising_steep_thick</th>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>-0.057152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_rising_steep_thick</th>\n",
       "      <td>0.506250</td>\n",
       "      <td>0.423881</td>\n",
       "      <td>-0.082369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_rising_steep_thin</th>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.488060</td>\n",
       "      <td>-0.105690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Real (0) mean  Fake (1) mean  Fake-Real\n",
       "concept name                                                             \n",
       "short_rising_steep_thin                0.606250       0.619403   0.013153\n",
       "long_dropping_flat_thick_Vibrato       0.606250       0.605970  -0.000280\n",
       "long_constant_thick_Vibrato            0.664583       0.643284  -0.021300\n",
       "long_rising_flat_thick                 0.593750       0.564179  -0.029571\n",
       "short_dropping_steep_thin              0.608333       0.577612  -0.030721\n",
       "long_dropping_flat_thick               0.643750       0.611940  -0.031810\n",
       "short_constant_thick                   0.672917       0.635821  -0.037096\n",
       "short_dropping_steep_thick             0.656250       0.617910  -0.038340\n",
       "long_dropping_steep_thick              0.593750       0.555224  -0.038526\n",
       "long_constant_thick                    0.639583       0.600000  -0.039583\n",
       "long_dropping_steep_thin               0.597917       0.556716  -0.041200\n",
       "short_rising_steep_thick               0.654167       0.597015  -0.057152\n",
       "long_rising_steep_thick                0.506250       0.423881  -0.082369\n",
       "long_rising_steep_thin                 0.593750       0.488060  -0.105690"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "if not df_tcav.empty:\n",
    "    summary = (\n",
    "        df_tcav.groupby([\"concept name\", \"true label\"])[\"positive percentage\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .pivot(index=\"concept name\", columns=\"true label\", values=\"positive percentage\")\n",
    "    )\n",
    "    summary.columns = [\"Real (0) mean\", \"Fake (1) mean\"]\n",
    "    summary[\"Fake-Real\"] = summary[\"Fake (1) mean\"] - summary[\"Real (0) mean\"]\n",
    "    display(summary.sort_values(\"Fake-Real\", ascending=False).head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_asv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
