{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# TCAV on ASVspoof5 Train-Only Subset (ReDimNet + Spoof Wrapper)\n",
        "\n",
        "This notebook runs TCAV on the **train-only ASVspoof5 subset** you prepared (`A/B/C = 30/15/5`, 50 speakers total).\n",
        "\n",
        "Key choices in this version:\n",
        "- Consistent labels with explicit enum:\n",
        "  - `label_str in {bonafide, spoof}`\n",
        "  - `label_id: bonafide=0, spoof=1`\n",
        "- `TARGET_CLASS_ID = 1` (spoof) in wrapper logits `[bonafide, spoof]`\n",
        "- **Recompute CAVs** (configurable, default `True`)\n",
        "- Faster/safer CSV generation via:\n",
        "  - checkpoint chunk writes (`CHECKPOINT_EVERY_N`)\n",
        "  - resume support (`RESUME_FROM_PARTIAL`)\n",
        "  - optional mel cache to disk (`ENABLE_MEL_CACHE`)\n",
        "\n",
        "Expected server location for this notebook:\n",
        "- `/home/SpeakerRec/BioVoice/redimnet/tcav/deepfakes/asvspoof5/`\n",
        "\n",
        "Expected inputs already uploaded on SSH:\n",
        "- `asvspoof5_train_only_selected_utterances_plan.csv` (in same folder as this notebook)\n",
        "- subset audio root: `/home/SpeakerRec/BioVoice/data/datasets/asvspoof5_train_only_subset_audio` with folders `A/`, `B/`, `C/`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "1e3f2b44",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch: 2.1.2+cu121\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Imports\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from captum.concept import TCAV, Concept\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "print('torch:', torch.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "88572a64",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NOTEBOOK_DIR = /home/SpeakerRec/BioVoice/redimnet/tcav/deepfakes/asvspoof5\n",
            "PLAN_CSV = /home/SpeakerRec/BioVoice/redimnet/tcav/deepfakes/asvspoof5/asvspoof5_train_only_selected_utterances_plan.csv | exists = True\n",
            "AUDIO_ROOT = /home/SpeakerRec/BioVoice/data/datasets/asvspoof5_train_only_subset_audio | exists = True\n",
            "CONCEPT_ROOT = /home/SpeakerRec/BioVoice/concept/final_concepts | exists = True\n",
            "LOGREG_PATH = /home/SpeakerRec/BioVoice/data/models/asvspoof_probe_50_50/logistic_regression.pkl | exists = True\n",
            "SCALER_PATH = /home/SpeakerRec/BioVoice/data/models/asvspoof_probe_50_50/scaler.pkl | exists = True\n",
            "RUN_DIR = /home/SpeakerRec/BioVoice/data/tcav/ASVspoof5_train_only_stage4_spoofwrapper\n",
            "PREPROCESS_DEVICE = cpu\n",
            "TCAV_DEVICE = cpu\n",
            "MODEL_DEVICE = cpu\n",
            "TARGET_CLASS_ID = 1 ( spoof )\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Paths + config (SSH defaults)\n",
        "PROJECT_ROOT = Path('/home/SpeakerRec/BioVoice')\n",
        "sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "# Notebook folder contains the uploaded plan CSVs\n",
        "NOTEBOOK_DIR = PROJECT_ROOT / 'redimnet' / 'tcav' / 'deepfakes' / 'asvspoof5'\n",
        "PLAN_CSV = NOTEBOOK_DIR / 'asvspoof5_train_only_selected_utterances_plan.csv'\n",
        "PLAN_SUMMARY_JSON = NOTEBOOK_DIR / 'asvspoof5_train_only_plan_summary.json'\n",
        "\n",
        "# Extracted train-only subset audio root created from your local extraction+zip pipeline\n",
        "AUDIO_ROOT = PROJECT_ROOT / 'data' / 'datasets' / 'asvspoof5_train_only_subset_audio'\n",
        "\n",
        "# Concepts + probe (same style as previous notebook; adjust if needed)\n",
        "CONCEPT_ROOT = PROJECT_ROOT / 'concept' / 'final_concepts'\n",
        "MODEL_DIR = PROJECT_ROOT / 'data' / 'models' / 'asvspoof_probe_50_50'\n",
        "LOGREG_PATH = MODEL_DIR / 'logistic_regression.pkl'\n",
        "SCALER_PATH = MODEL_DIR / 'scaler.pkl'\n",
        "\n",
        "OUT_DIR = PROJECT_ROOT / 'data' / 'tcav'\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "RUN_TAG = 'ASVspoof5_train_only_stage4_spoofwrapper'\n",
        "RUN_DIR = OUT_DIR / RUN_TAG\n",
        "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Device controls\n",
        "# PREPROCESS_DEVICE can use GPU to speed up audio->mel preprocessing (ReDimNet.spec).\n",
        "# TCAV_DEVICE controls where the TCAV wrapper model runs.\n",
        "# If TCAV_DEVICE stays CPU, only preprocessing gets GPU acceleration.\n",
        "# PREPROCESS_DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "PREPROCESS_DEVICE = torch.device('cpu')\n",
        "TCAV_DEVICE = torch.device('cpu')\n",
        "\n",
        "# Wrapper/model device used by TCAV interpret()\n",
        "MODEL_DEVICE = TCAV_DEVICE\n",
        "\n",
        "# Label enum (keep this consistent everywhere)\n",
        "LABEL_TO_ID = {'bonafide': 0, 'spoof': 1}\n",
        "ID_TO_LABEL = {v: k for k, v in LABEL_TO_ID.items()}\n",
        "TARGET_CLASS_NAME = 'spoof'\n",
        "TARGET_CLASS_ID = LABEL_TO_ID[TARGET_CLASS_NAME]  # wrapper logits index [bonafide, spoof]\n",
        "\n",
        "# Run controls\n",
        "RUN_GROUPS = ['A', 'B', 'C']          # You can set ['A'] for first run if needed\n",
        "MAX_SAMPLES = None                    # e.g. 100 for smoke test\n",
        "RECOMPUTE_CAVS = True                 # user requested: recompute CAVs\n",
        "CHECKPOINT_EVERY_N = 50               # write partial CSV every N samples\n",
        "RESUME_FROM_PARTIAL = False            # skip already processed utt_id if partial CSV exists\n",
        "\n",
        "# Speed / reliability helpers for the CSV-generation stage\n",
        "ENABLE_MEL_CACHE = True\n",
        "MEL_CACHE_DIR = RUN_DIR / 'mel_cache_stage4_inputs'\n",
        "MEL_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "PARTIAL_CSV = RUN_DIR / f'{RUN_TAG}__partial.csv'\n",
        "FINAL_CSV = RUN_DIR / f'{RUN_TAG}.csv'\n",
        "PROGRESS_JSON = RUN_DIR / f'{RUN_TAG}__progress.json'\n",
        "CAV_ACC_CSV = RUN_DIR / f'{RUN_TAG}__concept_cav_acc.csv'\n",
        "\n",
        "print('NOTEBOOK_DIR =', NOTEBOOK_DIR)\n",
        "print('PLAN_CSV =', PLAN_CSV, '| exists =', PLAN_CSV.exists())\n",
        "print('AUDIO_ROOT =', AUDIO_ROOT, '| exists =', AUDIO_ROOT.exists())\n",
        "print('CONCEPT_ROOT =', CONCEPT_ROOT, '| exists =', CONCEPT_ROOT.exists())\n",
        "print('LOGREG_PATH =', LOGREG_PATH, '| exists =', LOGREG_PATH.exists())\n",
        "print('SCALER_PATH =', SCALER_PATH, '| exists =', SCALER_PATH.exists())\n",
        "print('RUN_DIR =', RUN_DIR)\n",
        "print('PREPROCESS_DEVICE =', PREPROCESS_DEVICE)\n",
        "print('TCAV_DEVICE =', TCAV_DEVICE)\n",
        "print('MODEL_DEVICE =', MODEL_DEVICE)\n",
        "print('TARGET_CLASS_ID =', TARGET_CLASS_ID, '(', TARGET_CLASS_NAME, ')')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f6d72a1f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plan rows total: 3200\n",
            "Rows with missing audio_path: 0\n",
            "Run rows: 3200\n",
            "Groups: {'A': 1920, 'B': 960, 'C': 320}\n",
            "Labels: {'bonafide': 1600, 'spoof': 1600}\n",
            "Spoof systems: ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>group</th>\n",
              "      <th>partition</th>\n",
              "      <th>speaker_id</th>\n",
              "      <th>utt_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>label</th>\n",
              "      <th>system_id</th>\n",
              "      <th>codec_id</th>\n",
              "      <th>codec_q</th>\n",
              "      <th>source_utt_id</th>\n",
              "      <th>attack_codec_id</th>\n",
              "      <th>selected_reason</th>\n",
              "      <th>label_id</th>\n",
              "      <th>audio_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>train</td>\n",
              "      <td>T_0170</td>\n",
              "      <td>T_0000003481</td>\n",
              "      <td>F</td>\n",
              "      <td>bonafide</td>\n",
              "      <td>bonafide</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>bonafide_quota</td>\n",
              "      <td>0</td>\n",
              "      <td>/home/SpeakerRec/BioVoice/data/datasets/asvspo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A</td>\n",
              "      <td>train</td>\n",
              "      <td>T_0170</td>\n",
              "      <td>T_0000012452</td>\n",
              "      <td>F</td>\n",
              "      <td>bonafide</td>\n",
              "      <td>bonafide</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>bonafide_quota</td>\n",
              "      <td>0</td>\n",
              "      <td>/home/SpeakerRec/BioVoice/data/datasets/asvspo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A</td>\n",
              "      <td>train</td>\n",
              "      <td>T_0170</td>\n",
              "      <td>T_0000014646</td>\n",
              "      <td>F</td>\n",
              "      <td>bonafide</td>\n",
              "      <td>bonafide</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>bonafide_quota</td>\n",
              "      <td>0</td>\n",
              "      <td>/home/SpeakerRec/BioVoice/data/datasets/asvspo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A</td>\n",
              "      <td>train</td>\n",
              "      <td>T_0170</td>\n",
              "      <td>T_0000018611</td>\n",
              "      <td>F</td>\n",
              "      <td>bonafide</td>\n",
              "      <td>bonafide</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>bonafide_quota</td>\n",
              "      <td>0</td>\n",
              "      <td>/home/SpeakerRec/BioVoice/data/datasets/asvspo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A</td>\n",
              "      <td>train</td>\n",
              "      <td>T_0170</td>\n",
              "      <td>T_0000023686</td>\n",
              "      <td>F</td>\n",
              "      <td>bonafide</td>\n",
              "      <td>bonafide</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>bonafide_quota</td>\n",
              "      <td>0</td>\n",
              "      <td>/home/SpeakerRec/BioVoice/data/datasets/asvspo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  group partition speaker_id        utt_id gender     label system_id  \\\n",
              "0     A     train     T_0170  T_0000003481      F  bonafide  bonafide   \n",
              "1     A     train     T_0170  T_0000012452      F  bonafide  bonafide   \n",
              "2     A     train     T_0170  T_0000014646      F  bonafide  bonafide   \n",
              "3     A     train     T_0170  T_0000018611      F  bonafide  bonafide   \n",
              "4     A     train     T_0170  T_0000023686      F  bonafide  bonafide   \n",
              "\n",
              "  codec_id codec_q source_utt_id attack_codec_id selected_reason  label_id  \\\n",
              "0        -       -             -               -  bonafide_quota         0   \n",
              "1        -       -             -               -  bonafide_quota         0   \n",
              "2        -       -             -               -  bonafide_quota         0   \n",
              "3        -       -             -               -  bonafide_quota         0   \n",
              "4        -       -             -               -  bonafide_quota         0   \n",
              "\n",
              "                                          audio_path  \n",
              "0  /home/SpeakerRec/BioVoice/data/datasets/asvspo...  \n",
              "1  /home/SpeakerRec/BioVoice/data/datasets/asvspo...  \n",
              "2  /home/SpeakerRec/BioVoice/data/datasets/asvspo...  \n",
              "3  /home/SpeakerRec/BioVoice/data/datasets/asvspo...  \n",
              "4  /home/SpeakerRec/BioVoice/data/datasets/asvspo...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Load subset plan and build SSH audio paths (no local paths used)\n",
        "assert PLAN_CSV.exists(), f'Missing plan CSV: {PLAN_CSV}'\n",
        "assert AUDIO_ROOT.exists(), f'Missing subset audio root: {AUDIO_ROOT}'\n",
        "\n",
        "plan_df = pd.read_csv(PLAN_CSV)\n",
        "required_cols = {'group','partition','speaker_id','utt_id','gender','label','system_id'}\n",
        "missing = sorted(required_cols - set(plan_df.columns))\n",
        "assert not missing, f'Missing columns in plan CSV: {missing}'\n",
        "\n",
        "plan_df['utt_id'] = plan_df['utt_id'].astype(str)\n",
        "plan_df['speaker_id'] = plan_df['speaker_id'].astype(str)\n",
        "plan_df['group'] = plan_df['group'].astype(str)\n",
        "plan_df['label'] = plan_df['label'].astype(str)\n",
        "plan_df['label_id'] = plan_df['label'].map(LABEL_TO_ID)\n",
        "assert plan_df['label_id'].notna().all(), 'Unexpected label values in plan CSV'\n",
        "plan_df['label_id'] = plan_df['label_id'].astype(int)\n",
        "\n",
        "# Reconstruct audio path by extraction convention: AUDIO_ROOT/{group}/{label}/{utt_id}.flac (or .wav fallback)\n",
        "def resolve_audio_path(row):\n",
        "    p_flac = AUDIO_ROOT / row['group'] / row['label'] / f\"{row['utt_id']}.flac\"\n",
        "    if p_flac.exists():\n",
        "        return str(p_flac)\n",
        "    p_wav = AUDIO_ROOT / row['group'] / row['label'] / f\"{row['utt_id']}.wav\"\n",
        "    if p_wav.exists():\n",
        "        return str(p_wav)\n",
        "    return None\n",
        "\n",
        "plan_df['audio_path'] = plan_df.apply(resolve_audio_path, axis=1)\n",
        "missing_audio = plan_df['audio_path'].isna().sum()\n",
        "print('Plan rows total:', len(plan_df))\n",
        "print('Rows with missing audio_path:', int(missing_audio))\n",
        "assert missing_audio == 0, 'Some audio files are missing under AUDIO_ROOT. Check uploaded subset folders.'\n",
        "\n",
        "# Filter groups for this run\n",
        "run_df = plan_df[plan_df['group'].isin(RUN_GROUPS)].copy().reset_index(drop=True)\n",
        "if MAX_SAMPLES is not None:\n",
        "    run_df = run_df.head(int(MAX_SAMPLES)).copy().reset_index(drop=True)\n",
        "\n",
        "print('Run rows:', len(run_df))\n",
        "print('Groups:', run_df['group'].value_counts().sort_index().to_dict())\n",
        "print('Labels:', run_df['label'].value_counts().sort_index().to_dict())\n",
        "print('Spoof systems:', sorted(run_df.loc[run_df['label']=='spoof','system_id'].unique().tolist()))\n",
        "display(run_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "2a75ebf3",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/SpeakerRec/.cache/torch/hub/IDRnD_ReDimNet_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded ReDimNet. N_MELS = 72\n",
            "Loaded probe: <class 'sklearn.linear_model._logistic.LogisticRegression'> <class 'sklearn.preprocessing._data.StandardScaler'>\n",
            "Created ReDimNetSpoofWrapper. Logits order = [bonafide, spoof]\n",
            "Note: If TCAV_DEVICE=cpu, the wrapper forward (backbone+embedding+probe) still runs on CPU.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Audio loader + ReDimNet + wrapper probe\n",
        "# Uses soundfile if available, falls back to torchaudio.\n",
        "try:\n",
        "    import soundfile as sf\n",
        "    _HAS_SF = True\n",
        "except Exception:\n",
        "    sf = None\n",
        "    _HAS_SF = False\n",
        "    import torchaudio\n",
        "\n",
        "\n",
        "def load_audio_16k_mono(audio_path: str) -> np.ndarray:\n",
        "    p = str(audio_path)\n",
        "    if _HAS_SF:\n",
        "        wav, sr = sf.read(p)\n",
        "        if wav.ndim == 2:\n",
        "            wav = wav.mean(axis=1)\n",
        "        wav = wav.astype(np.float32)\n",
        "        if sr != 16000:\n",
        "            # light fallback via torchaudio for resampling if needed\n",
        "            w = torch.tensor(wav, dtype=torch.float32).unsqueeze(0)\n",
        "            w = torchaudio.functional.resample(w, sr, 16000)\n",
        "            wav = w.squeeze(0).cpu().numpy().astype(np.float32)\n",
        "        return wav\n",
        "    else:\n",
        "        w, sr = torchaudio.load(p)\n",
        "        if w.shape[0] > 1:\n",
        "            w = w.mean(dim=0, keepdim=True)\n",
        "        if sr != 16000:\n",
        "            w = torchaudio.functional.resample(w, sr, 16000)\n",
        "        return w.squeeze(0).cpu().numpy().astype(np.float32)\n",
        "\n",
        "# Load ReDimNet\n",
        "redim_model = (\n",
        "    torch.hub.load(\n",
        "        'IDRnD/ReDimNet',\n",
        "        'ReDimNet',\n",
        "        model_name='b5',\n",
        "        train_type='ptn',\n",
        "        dataset='vox2',\n",
        "    )\n",
        "    .to(MODEL_DEVICE)\n",
        "    .eval()\n",
        ")\n",
        "\n",
        "with torch.no_grad():\n",
        "    dummy_wav = torch.zeros(1, 16000, device=MODEL_DEVICE)\n",
        "    dummy_mel = redim_model.spec(dummy_wav)\n",
        "N_MELS = int(dummy_mel.shape[1])\n",
        "print('Loaded ReDimNet. N_MELS =', N_MELS)\n",
        "\n",
        "# Load scaler + logistic probe\n",
        "with open(LOGREG_PATH, 'rb') as f:\n",
        "    logreg_clf = pickle.load(f)\n",
        "with open(SCALER_PATH, 'rb') as f:\n",
        "    scaler = pickle.load(f)\n",
        "print('Loaded probe:', type(logreg_clf), type(scaler))\n",
        "\n",
        "class ReDimNetSpoofWrapper(nn.Module):\n",
        "    def __init__(self, redim_model, W, b, mean, scale, l2_norm_emb=True):\n",
        "        super().__init__()\n",
        "        self.redim = redim_model\n",
        "        self.l2_norm_emb = l2_norm_emb\n",
        "        D = W.shape[1]\n",
        "        self.register_buffer('mean', torch.tensor(mean, dtype=torch.float32))\n",
        "        self.register_buffer('scale', torch.tensor(scale, dtype=torch.float32))\n",
        "        self.linear = nn.Linear(D, 1)\n",
        "        self.linear.weight.data = torch.tensor(W, dtype=torch.float32)\n",
        "        self.linear.bias.data = torch.tensor(b, dtype=torch.float32)\n",
        "\n",
        "    def forward(self, mel4d):\n",
        "        x = self.redim.backbone(mel4d)\n",
        "        x = self.redim.pool(x)\n",
        "        x = self.redim.bn(x)\n",
        "        emb = self.redim.linear(x)\n",
        "        if self.l2_norm_emb:\n",
        "            emb = emb / (emb.norm(p=2, dim=1, keepdim=True) + 1e-12)\n",
        "        emb = (emb - self.mean) / self.scale\n",
        "        score = self.linear(emb)  # [B,1]\n",
        "        logits = torch.cat([-score, score], dim=1)  # [B,2] = [bonafide, spoof]\n",
        "        return logits\n",
        "\n",
        "spoof_model = ReDimNetSpoofWrapper(\n",
        "    redim_model,\n",
        "    W=logreg_clf.coef_,\n",
        "    b=logreg_clf.intercept_,\n",
        "    mean=scaler.mean_,\n",
        "    scale=scaler.scale_,\n",
        ").to(MODEL_DEVICE).eval()\n",
        "\n",
        "print('Created ReDimNetSpoofWrapper. Logits order = [bonafide, spoof]')\n",
        "print('Note: If TCAV_DEVICE=cpu, the wrapper forward (backbone+embedding+probe) still runs on CPU.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "69a3cb03",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First concept batch shape: (16, 1, 72, 304)\n",
            "First random batch shape: (16, 1, 72, 304)\n",
            "Layer: stage4 -> redim.backbone.stage4.2\n",
            "Prepared 28 concepts + random.\n",
            "FORCE_TRAIN_CAVS = True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/SpeakerRec/BioVoice/.venv_asv/lib/python3.10/site-packages/captum/concept/_utils/classifier.py:130: UserWarning: Using default classifier for TCAV which keeps input both train and test datasets in the memory. Consider defining your own classifier that doesn't rely heavily on memory, for large number of concepts, by extending `Classifer` abstract class\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Concepts + TCAV setup (recompute CAVs by default)\n",
        "assert CONCEPT_ROOT.exists(), f'Missing concept root: {CONCEPT_ROOT}'\n",
        "\n",
        "# Random concept creation (auto-generate if missing)\n",
        "AUTO_CREATE_RANDOM_CONCEPT = True\n",
        "RANDOM_CONCEPT_NAME = 'random'\n",
        "RANDOM_CONCEPT_N = 60\n",
        "RANDOM_CONCEPT_SEED = 42\n",
        "\n",
        "# Minimal concept dataset for Captum Concept/DataLoader using .npy files in concept folders\n",
        "class NpyConceptDataset(Dataset):\n",
        "    def __init__(self, npy_files: list[Path]):\n",
        "        self.npy_files = list(npy_files)\n",
        "    def __len__(self):\n",
        "        return len(self.npy_files)\n",
        "    def __getitem__(self, idx):\n",
        "        arr = np.load(self.npy_files[idx]).astype(np.float32)\n",
        "        x = torch.tensor(arr)\n",
        "        # Expected per-sample shape for ReDimNet conv input is [1, H, W].\n",
        "        # Many concept files are saved as [H, W], so add the channel dim.\n",
        "        if x.ndim == 2:\n",
        "            x = x.unsqueeze(0)\n",
        "        elif x.ndim == 3 and x.shape[0] != 1 and x.shape[-1] == 1:\n",
        "            # Convert [H, W, 1] -> [1, H, W] if needed.\n",
        "            x = x.permute(2, 0, 1)\n",
        "        if x.ndim != 3 or x.shape[0] != 1:\n",
        "            raise RuntimeError(f'Unexpected concept tensor shape {tuple(x.shape)} in {self.npy_files[idx]} (expected [1,H,W])')\n",
        "        return x\n",
        "\n",
        "def concept_loader_from_dir(cdir: Path, batch_size: int = 16) -> DataLoader:\n",
        "    npy_files = sorted(list(cdir.glob('*.npy')))\n",
        "    assert len(npy_files) > 0, f'No .npy files in concept dir: {cdir}'\n",
        "    ds = NpyConceptDataset(npy_files)\n",
        "    return DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "concept_dirs = [p for p in sorted(CONCEPT_ROOT.iterdir()) if p.is_dir() and p.name != RANDOM_CONCEPT_NAME]\n",
        "assert len(concept_dirs) > 0, f'No concept directories found in {CONCEPT_ROOT}'\n",
        "\n",
        "positive_concepts = []\n",
        "for idx, cdir in enumerate(concept_dirs):\n",
        "    dl = concept_loader_from_dir(cdir)\n",
        "    positive_concepts.append(Concept(id=idx, name=cdir.name, data_iter=dl))\n",
        "\n",
        "# random concept directory (TCAV baseline). If missing, optionally auto-create by mixing samples from other concepts.\n",
        "random_dir = CONCEPT_ROOT / RANDOM_CONCEPT_NAME\n",
        "if (not random_dir.exists()) and AUTO_CREATE_RANDOM_CONCEPT:\n",
        "    random_dir.mkdir(parents=True, exist_ok=True)\n",
        "    pool = []\n",
        "    for cdir in concept_dirs:\n",
        "        pool.extend(sorted(cdir.glob('*.npy')))\n",
        "    if len(pool) < RANDOM_CONCEPT_N:\n",
        "        raise RuntimeError(f'Not enough .npy files to create random concept: pool={len(pool)} need={RANDOM_CONCEPT_N}')\n",
        "    rng = np.random.default_rng(RANDOM_CONCEPT_SEED)\n",
        "    chosen = rng.choice(np.array(pool, dtype=object), size=RANDOM_CONCEPT_N, replace=False)\n",
        "    # Copy files into random/ with stable numbering (keeps original concept dirs untouched).\n",
        "    import shutil\n",
        "    for i, src_npy in enumerate(chosen, start=1):\n",
        "        dst = random_dir / f\"{i:06d}.npy\"\n",
        "        shutil.copy2(Path(src_npy), dst)\n",
        "    # Basic metadata for traceability\n",
        "    (random_dir / 'meta.json').write_text(json.dumps({\n",
        "        'kind': 'auto_random_mixed_concepts',\n",
        "        'n_files': RANDOM_CONCEPT_N,\n",
        "        'seed': RANDOM_CONCEPT_SEED,\n",
        "        'source_root': str(CONCEPT_ROOT),\n",
        "        'excluded_dir': RANDOM_CONCEPT_NAME,\n",
        "    }, indent=2), encoding='utf-8')\n",
        "    print(f'[INFO] Auto-created random concept at {random_dir} with {RANDOM_CONCEPT_N} mixed .npy files')\n",
        "\n",
        "if random_dir.exists() and random_dir.is_dir():\n",
        "    rand_dl = concept_loader_from_dir(random_dir)\n",
        "else:\n",
        "    raise RuntimeError(f'Missing random concept directory: {random_dir}. Set AUTO_CREATE_RANDOM_CONCEPT=True or create {random_dir}/*.npy')\n",
        "\n",
        "random_concept = Concept(id=len(positive_concepts), name=RANDOM_CONCEPT_NAME, data_iter=rand_dl)\n",
        "experimental_sets = [[c, random_concept] for c in positive_concepts]\n",
        "\n",
        "# Shape sanity checks (common TCAV failure point)\n",
        "first_concept_batch = next(iter(positive_concepts[0].data_iter))\n",
        "first_random_batch = next(iter(random_concept.data_iter))\n",
        "print('First concept batch shape:', tuple(first_concept_batch.shape))\n",
        "print('First random batch shape:', tuple(first_random_batch.shape))\n",
        "assert first_concept_batch.ndim == 4 and first_concept_batch.shape[1] == 1,     f'Concept batch must be [B,1,H,W], got {tuple(first_concept_batch.shape)}'\n",
        "assert first_random_batch.ndim == 4 and first_random_batch.shape[1] == 1,     f'Random concept batch must be [B,1,H,W], got {tuple(first_random_batch.shape)}'\n",
        "\n",
        "TARGET_LAYERS = {\n",
        "    'stage4': redim_model.backbone.stage4[2],\n",
        "}\n",
        "\n",
        "all_tcav = {}\n",
        "for layer_key, layer_module in TARGET_LAYERS.items():\n",
        "    layer_name = getattr(layer_module, 'layer_name', None) or 'redim.backbone.stage4.2'\n",
        "    print('Layer:', layer_key, '->', layer_name)\n",
        "    all_tcav[layer_key] = TCAV(spoof_model, [layer_name], test_split_ratio=0.33)\n",
        "\n",
        "FORCE_TRAIN_CAVS = bool(RECOMPUTE_CAVS)\n",
        "print('Prepared', len(positive_concepts), 'concepts + random.')\n",
        "print('FORCE_TRAIN_CAVS =', FORCE_TRAIN_CAVS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "8b9fbad9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing CAV accuracies...\n",
            "stage4 rows: 28\n",
            "Saved CAV acc -> /home/SpeakerRec/BioVoice/data/tcav/ASVspoof5_train_only_stage4_spoofwrapper/ASVspoof5_train_only_stage4_spoofwrapper__concept_cav_acc.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>layer_key</th>\n",
              "      <th>concept_name</th>\n",
              "      <th>layer_name</th>\n",
              "      <th>cav_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stage4</td>\n",
              "      <td>arch_long_thick</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.461538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>stage4</td>\n",
              "      <td>arch_long_thin</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.512821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>stage4</td>\n",
              "      <td>arch_short_thick</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.435897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>stage4</td>\n",
              "      <td>arch_short_thin</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.512821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>stage4</td>\n",
              "      <td>const_long_thick</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.694915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>stage4</td>\n",
              "      <td>const_long_thin</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.661017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>stage4</td>\n",
              "      <td>const_short_thick</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.644068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>stage4</td>\n",
              "      <td>const_short_thin</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.661017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>stage4</td>\n",
              "      <td>dropping_long_thick</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.692308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>stage4</td>\n",
              "      <td>dropping_long_thin</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.487179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>stage4</td>\n",
              "      <td>dropping_short_thick</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.435897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>stage4</td>\n",
              "      <td>dropping_short_thin</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.461538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>stage4</td>\n",
              "      <td>dropping_steep_long_thick</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.564103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>stage4</td>\n",
              "      <td>dropping_steep_long_thin</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.410256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>stage4</td>\n",
              "      <td>dropping_steep_short_thick</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.487179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>stage4</td>\n",
              "      <td>dropping_steep_short_thin</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.589744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>stage4</td>\n",
              "      <td>parabola_long_thick</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.384615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>stage4</td>\n",
              "      <td>parabola_long_thin</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.564103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>stage4</td>\n",
              "      <td>parabola_short_thick</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.564103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>stage4</td>\n",
              "      <td>parabola_short_thin</td>\n",
              "      <td>redim.backbone.stage4.2</td>\n",
              "      <td>0.461538</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   layer_key                concept_name               layer_name   cav_acc\n",
              "0     stage4             arch_long_thick  redim.backbone.stage4.2  0.461538\n",
              "1     stage4              arch_long_thin  redim.backbone.stage4.2  0.512821\n",
              "2     stage4            arch_short_thick  redim.backbone.stage4.2  0.435897\n",
              "3     stage4             arch_short_thin  redim.backbone.stage4.2  0.512821\n",
              "4     stage4            const_long_thick  redim.backbone.stage4.2  0.694915\n",
              "5     stage4             const_long_thin  redim.backbone.stage4.2  0.661017\n",
              "6     stage4           const_short_thick  redim.backbone.stage4.2  0.644068\n",
              "7     stage4            const_short_thin  redim.backbone.stage4.2  0.661017\n",
              "8     stage4         dropping_long_thick  redim.backbone.stage4.2  0.692308\n",
              "9     stage4          dropping_long_thin  redim.backbone.stage4.2  0.487179\n",
              "10    stage4        dropping_short_thick  redim.backbone.stage4.2  0.435897\n",
              "11    stage4         dropping_short_thin  redim.backbone.stage4.2  0.461538\n",
              "12    stage4   dropping_steep_long_thick  redim.backbone.stage4.2  0.564103\n",
              "13    stage4    dropping_steep_long_thin  redim.backbone.stage4.2  0.410256\n",
              "14    stage4  dropping_steep_short_thick  redim.backbone.stage4.2  0.487179\n",
              "15    stage4   dropping_steep_short_thin  redim.backbone.stage4.2  0.589744\n",
              "16    stage4         parabola_long_thick  redim.backbone.stage4.2  0.384615\n",
              "17    stage4          parabola_long_thin  redim.backbone.stage4.2  0.564103\n",
              "18    stage4        parabola_short_thick  redim.backbone.stage4.2  0.564103\n",
              "19    stage4         parabola_short_thin  redim.backbone.stage4.2  0.461538"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Compute and save CAV accuracies (recomputed if FORCE_TRAIN_CAVS=True)\n",
        "def compute_cav_acc_df(tcav: TCAV, positive_concepts: list[Concept], random_concept: Concept, layer_key: str) -> pd.DataFrame:\n",
        "    cavs_dict = tcav.compute_cavs([[c, random_concept] for c in positive_concepts], force_train=FORCE_TRAIN_CAVS)\n",
        "    rows = []\n",
        "    for concepts_key, layer_map in cavs_dict.items():\n",
        "        try:\n",
        "            pos_id = int(str(concepts_key).split('-')[0])\n",
        "        except Exception:\n",
        "            continue\n",
        "        if not (0 <= pos_id < len(positive_concepts)):\n",
        "            continue\n",
        "        concept_name = positive_concepts[pos_id].name\n",
        "        for layer_name, cav_obj in layer_map.items():\n",
        "            if cav_obj is None or cav_obj.stats is None:\n",
        "                continue\n",
        "            acc = cav_obj.stats.get('accs', None)\n",
        "            if acc is None:\n",
        "                acc = cav_obj.stats.get('acc', None)\n",
        "            if isinstance(acc, torch.Tensor):\n",
        "                acc = acc.detach().cpu().item()\n",
        "            rows.append({\n",
        "                'layer_key': layer_key,\n",
        "                'concept_name': concept_name,\n",
        "                'layer_name': layer_name,\n",
        "                'cav_acc': float(acc) if acc is not None else np.nan,\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "print('Computing CAV accuracies...')\n",
        "acc_dfs = []\n",
        "for layer_key, tcav in all_tcav.items():\n",
        "    df_acc = compute_cav_acc_df(tcav, positive_concepts, random_concept, layer_key)\n",
        "    print(layer_key, 'rows:', len(df_acc))\n",
        "    acc_dfs.append(df_acc)\n",
        "acc_df_combined = pd.concat(acc_dfs, ignore_index=True) if acc_dfs else pd.DataFrame()\n",
        "acc_df_combined.to_csv(CAV_ACC_CSV, index=False)\n",
        "print('Saved CAV acc ->', CAV_ACC_CSV)\n",
        "display(acc_df_combined.head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ENABLE_MEL_CACHE = True\n",
            "MEL_CACHE_DIR = /home/SpeakerRec/BioVoice/data/tcav/ASVspoof5_train_only_stage4_spoofwrapper/mel_cache_stage4_inputs\n"
          ]
        }
      ],
      "source": [
        "# Mel preprocessing helpers + optional disk cache\n",
        "TARGET_FRAMES = 304  # keep same style as prior notebook; adjust if your concept tensors expect a different length\n",
        "\n",
        "def fix_mel_frames(mel: torch.Tensor, target_frames: int) -> torch.Tensor:\n",
        "    # mel: (B, N_MELS, T)\n",
        "    T = mel.shape[-1]\n",
        "    if T == target_frames:\n",
        "        return mel\n",
        "    if T > target_frames:\n",
        "        return mel[..., :target_frames]\n",
        "    pad = target_frames - T\n",
        "    return F.pad(mel, (0, pad))\n",
        "\n",
        "def mel_cache_path_for_utt(utt_id: str) -> Path:\n",
        "    return MEL_CACHE_DIR / f'{utt_id}.npy'\n",
        "\n",
        "def waveform_to_mel4d_from_audio_path(audio_path: str, utt_id: str) -> torch.Tensor:\n",
        "    cache_path = mel_cache_path_for_utt(utt_id)\n",
        "    if ENABLE_MEL_CACHE and cache_path.exists():\n",
        "        arr = np.load(cache_path)\n",
        "        return torch.tensor(arr, dtype=torch.float32, device=PREPROCESS_DEVICE)\n",
        "\n",
        "    wav_np = load_audio_16k_mono(audio_path)\n",
        "    wav = torch.tensor(wav_np, dtype=torch.float32, device=PREPROCESS_DEVICE).unsqueeze(0)  # (1,T)\n",
        "    with torch.no_grad():\n",
        "        mel = redim_model.spec(wav)  # (1,N_MELS,Tm)\n",
        "    mel = fix_mel_frames(mel, TARGET_FRAMES)\n",
        "    mel4d = mel.unsqueeze(1)  # (1,1,N_MELS,TARGET_FRAMES)\n",
        "\n",
        "    if ENABLE_MEL_CACHE:\n",
        "        np.save(cache_path, mel4d.detach().cpu().numpy().astype(np.float32))\n",
        "    # TCAV wrapper runs on TCAV_DEVICE; move tensor explicitly before returning.\n",
        "    mel4d = mel4d.to(TCAV_DEVICE)\n",
        "    return mel4d\n",
        "\n",
        "print('ENABLE_MEL_CACHE =', ENABLE_MEL_CACHE)\n",
        "print('MEL_CACHE_DIR =', MEL_CACHE_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resume enabled = False | already processed utt_ids = 0\n",
            "[CHKPT] done=50 skipped=0 failed=0 elapsed=7.9 min\n",
            "[CHKPT] done=100 skipped=0 failed=0 elapsed=15.8 min\n",
            "[CHKPT] done=150 skipped=0 failed=0 elapsed=23.8 min\n",
            "[CHKPT] done=200 skipped=0 failed=0 elapsed=31.6 min\n",
            "[CHKPT] done=250 skipped=0 failed=0 elapsed=39.5 min\n",
            "[CHKPT] done=300 skipped=0 failed=0 elapsed=47.4 min\n",
            "[CHKPT] done=350 skipped=0 failed=0 elapsed=55.2 min\n",
            "[CHKPT] done=400 skipped=0 failed=0 elapsed=63.1 min\n",
            "[CHKPT] done=450 skipped=0 failed=0 elapsed=70.9 min\n",
            "[CHKPT] done=500 skipped=0 failed=0 elapsed=78.8 min\n",
            "[CHKPT] done=550 skipped=0 failed=0 elapsed=86.7 min\n",
            "[CHKPT] done=600 skipped=0 failed=0 elapsed=94.8 min\n",
            "[CHKPT] done=650 skipped=0 failed=0 elapsed=102.9 min\n",
            "[CHKPT] done=700 skipped=0 failed=0 elapsed=110.8 min\n",
            "[CHKPT] done=750 skipped=0 failed=0 elapsed=118.9 min\n",
            "[CHKPT] done=800 skipped=0 failed=0 elapsed=126.8 min\n",
            "[CHKPT] done=850 skipped=0 failed=0 elapsed=134.8 min\n",
            "[CHKPT] done=900 skipped=0 failed=0 elapsed=142.7 min\n",
            "[CHKPT] done=950 skipped=0 failed=0 elapsed=150.6 min\n",
            "[CHKPT] done=1000 skipped=0 failed=0 elapsed=158.6 min\n",
            "[CHKPT] done=1050 skipped=0 failed=0 elapsed=166.5 min\n",
            "[CHKPT] done=1100 skipped=0 failed=0 elapsed=174.5 min\n",
            "[CHKPT] done=1150 skipped=0 failed=0 elapsed=183.4 min\n",
            "[CHKPT] done=1200 skipped=0 failed=0 elapsed=191.8 min\n",
            "[CHKPT] done=1250 skipped=0 failed=0 elapsed=199.9 min\n",
            "[CHKPT] done=1300 skipped=0 failed=0 elapsed=208.2 min\n",
            "[CHKPT] done=1350 skipped=0 failed=0 elapsed=216.1 min\n",
            "[CHKPT] done=1400 skipped=0 failed=0 elapsed=224.0 min\n",
            "[CHKPT] done=1450 skipped=0 failed=0 elapsed=231.9 min\n",
            "[CHKPT] done=1500 skipped=0 failed=0 elapsed=239.7 min\n",
            "[CHKPT] done=1550 skipped=0 failed=0 elapsed=247.6 min\n",
            "[CHKPT] done=1600 skipped=0 failed=0 elapsed=255.5 min\n",
            "[CHKPT] done=1650 skipped=0 failed=0 elapsed=263.4 min\n",
            "[CHKPT] done=1700 skipped=0 failed=0 elapsed=271.3 min\n",
            "[CHKPT] done=1750 skipped=0 failed=0 elapsed=279.3 min\n",
            "[CHKPT] done=1800 skipped=0 failed=0 elapsed=287.2 min\n",
            "[CHKPT] done=1850 skipped=0 failed=0 elapsed=295.0 min\n",
            "[CHKPT] done=1900 skipped=0 failed=0 elapsed=302.9 min\n",
            "[CHKPT] done=1950 skipped=0 failed=0 elapsed=310.9 min\n",
            "[CHKPT] done=2000 skipped=0 failed=0 elapsed=318.8 min\n",
            "[CHKPT] done=2050 skipped=0 failed=0 elapsed=326.6 min\n",
            "[CHKPT] done=2100 skipped=0 failed=0 elapsed=334.5 min\n",
            "[CHKPT] done=2150 skipped=0 failed=0 elapsed=342.4 min\n",
            "[CHKPT] done=2200 skipped=0 failed=0 elapsed=350.4 min\n",
            "[CHKPT] done=2250 skipped=0 failed=0 elapsed=358.3 min\n",
            "[CHKPT] done=2300 skipped=0 failed=0 elapsed=366.2 min\n",
            "[CHKPT] done=2350 skipped=0 failed=0 elapsed=374.2 min\n",
            "[CHKPT] done=2400 skipped=0 failed=0 elapsed=382.1 min\n",
            "[CHKPT] done=2450 skipped=0 failed=0 elapsed=390.1 min\n",
            "[CHKPT] done=2500 skipped=0 failed=0 elapsed=398.0 min\n",
            "[CHKPT] done=2550 skipped=0 failed=0 elapsed=405.9 min\n",
            "[CHKPT] done=2600 skipped=0 failed=0 elapsed=413.9 min\n",
            "[CHKPT] done=2650 skipped=0 failed=0 elapsed=421.7 min\n",
            "[CHKPT] done=2700 skipped=0 failed=0 elapsed=429.6 min\n",
            "[CHKPT] done=2750 skipped=0 failed=0 elapsed=437.5 min\n",
            "[CHKPT] done=2800 skipped=0 failed=0 elapsed=445.4 min\n",
            "[CHKPT] done=2850 skipped=0 failed=0 elapsed=453.3 min\n",
            "[CHKPT] done=2900 skipped=0 failed=0 elapsed=461.2 min\n",
            "[CHKPT] done=2950 skipped=0 failed=0 elapsed=469.2 min\n",
            "[CHKPT] done=3000 skipped=0 failed=0 elapsed=477.2 min\n",
            "[CHKPT] done=3050 skipped=0 failed=0 elapsed=485.1 min\n",
            "[CHKPT] done=3100 skipped=0 failed=0 elapsed=493.1 min\n",
            "[CHKPT] done=3150 skipped=0 failed=0 elapsed=501.0 min\n",
            "[CHKPT] done=3200 skipped=0 failed=0 elapsed=508.9 min\n",
            "Scoring loop complete.\n",
            "done = 3200 | skipped = 0 | failed = 0\n",
            "Partial CSV = /home/SpeakerRec/BioVoice/data/tcav/ASVspoof5_train_only_stage4_spoofwrapper/ASVspoof5_train_only_stage4_spoofwrapper__partial.csv\n"
          ]
        }
      ],
      "source": [
        "# TCAV scoring loop -> CSV with checkpointing/resume (this is the expensive 'CSV creation' stage)\n",
        "# Output is long-format: one row per (sample, concept) per layer.\n",
        "\n",
        "\n",
        "def load_processed_utts_from_partial(partial_csv: Path) -> set[str]:\n",
        "    if (not RESUME_FROM_PARTIAL) or (not partial_csv.exists()):\n",
        "        return set()\n",
        "    try:\n",
        "        tmp = pd.read_csv(partial_csv)\n",
        "        if \"utt_id\" not in tmp.columns:\n",
        "            return set()\n",
        "        # Only treat utt_ids as processed if at least one non-error TCAV row exists.\n",
        "        if \"layer_key\" in tmp.columns:\n",
        "            tmp = tmp[tmp[\"layer_key\"] != \"ERROR\"]\n",
        "        return set(tmp[\"utt_id\"].astype(str).unique().tolist())\n",
        "    except Exception as e:\n",
        "        print(\"[WARN] Failed to read partial CSV for resume, starting fresh:\", e)\n",
        "        return set()\n",
        "\n",
        "\n",
        "def _scalarize_metric(x):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return float(x.detach().cpu().flatten()[0].item())\n",
        "    return float(np.array(x).flatten()[0])\n",
        "\n",
        "\n",
        "rows_buffer = []\n",
        "start_time = time.time()\n",
        "processed_utts = load_processed_utts_from_partial(PARTIAL_CSV)\n",
        "if (not RESUME_FROM_PARTIAL) and PARTIAL_CSV.exists():\n",
        "    print(\n",
        "        f\"[INFO] RESUME_FROM_PARTIAL=False -> removing old partial CSV: {PARTIAL_CSV}\"\n",
        "    )\n",
        "    PARTIAL_CSV.unlink()\n",
        "\n",
        "print(\n",
        "    \"Resume enabled =\",\n",
        "    RESUME_FROM_PARTIAL,\n",
        "    \"| already processed utt_ids =\",\n",
        "    len(processed_utts),\n",
        ")\n",
        "if PREPROCESS_DEVICE.type == \"cuda\" and TCAV_DEVICE.type == \"cpu\":\n",
        "    print(\n",
        "        \"[INFO] Using GPU for mel preprocessing only; TCAV wrapper forward runs on CPU. Inputs will be moved to TCAV_DEVICE before interpret().\"\n",
        "    )\n",
        "\n",
        "# Determine run order deterministically\n",
        "iter_df = run_df.copy()\n",
        "iter_df = iter_df.sort_values(\n",
        "    [\"group\", \"speaker_id\", \"label\", \"system_id\", \"utt_id\"]\n",
        ").reset_index(drop=True)\n",
        "\n",
        "n_total = len(iter_df)\n",
        "n_done = 0\n",
        "n_skipped = 0\n",
        "n_failed = 0\n",
        "\n",
        "for i, rec in iter_df.iterrows():\n",
        "    utt_id = str(rec[\"utt_id\"])\n",
        "    if utt_id in processed_utts:\n",
        "        n_skipped += 1\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        x = waveform_to_mel4d_from_audio_path(rec[\"audio_path\"], utt_id=utt_id)\n",
        "        # Defensive device alignment: cached/preprocessed tensors must match TCAV/model device\n",
        "        x = x.to(TCAV_DEVICE)\n",
        "\n",
        "        for layer_key, tcav in all_tcav.items():\n",
        "            score_for_label = tcav.interpret(\n",
        "                inputs=x,\n",
        "                experimental_sets=experimental_sets,\n",
        "                target=TARGET_CLASS_ID,\n",
        "            )\n",
        "\n",
        "            for exp_key, layer_dict in score_for_label.items():\n",
        "                try:\n",
        "                    pos_idx = int(str(exp_key).split(\"-\")[0])\n",
        "                except Exception:\n",
        "                    continue\n",
        "                if not (0 <= pos_idx < len(positive_concepts)):\n",
        "                    continue\n",
        "                concept_name = positive_concepts[pos_idx].name\n",
        "\n",
        "                for layer_name, metrics in layer_dict.items():\n",
        "                    sc = metrics.get(\"sign_count\")\n",
        "                    mg = metrics.get(\"magnitude\")\n",
        "                    if sc is None or mg is None:\n",
        "                        continue\n",
        "\n",
        "                    rows_buffer.append(\n",
        "                        {\n",
        "                            \"row_index\": int(i),\n",
        "                            \"utt_id\": utt_id,\n",
        "                            \"group\": str(rec[\"group\"]),\n",
        "                            \"partition\": str(rec[\"partition\"]),\n",
        "                            \"speaker_id\": str(rec[\"speaker_id\"]),\n",
        "                            \"gender\": str(rec[\"gender\"]),\n",
        "                            \"label_str\": str(rec[\"label\"]),\n",
        "                            \"label_id\": int(rec[\"label_id\"]),\n",
        "                            \"system_id\": str(rec[\"system_id\"]),\n",
        "                            \"target_class_name\": TARGET_CLASS_NAME,\n",
        "                            \"target_class_id\": int(TARGET_CLASS_ID),\n",
        "                            \"layer_key\": layer_key,\n",
        "                            \"concept_name\": concept_name,\n",
        "                            \"layer_name\": layer_name,\n",
        "                            \"positive_percentage\": _scalarize_metric(sc),\n",
        "                            \"magnitude\": _scalarize_metric(mg),\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "        processed_utts.add(utt_id)\n",
        "        n_done += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        n_failed += 1\n",
        "        rows_buffer.append(\n",
        "            {\n",
        "                \"row_index\": int(i),\n",
        "                \"utt_id\": utt_id,\n",
        "                \"group\": str(rec[\"group\"]),\n",
        "                \"partition\": str(rec[\"partition\"]),\n",
        "                \"speaker_id\": str(rec[\"speaker_id\"]),\n",
        "                \"gender\": str(rec[\"gender\"]),\n",
        "                \"label_str\": str(rec[\"label\"]),\n",
        "                \"label_id\": int(rec[\"label_id\"]),\n",
        "                \"system_id\": str(rec[\"system_id\"]),\n",
        "                \"target_class_name\": TARGET_CLASS_NAME,\n",
        "                \"target_class_id\": int(TARGET_CLASS_ID),\n",
        "                \"layer_key\": \"ERROR\",\n",
        "                \"concept_name\": \"ERROR\",\n",
        "                \"layer_name\": \"ERROR\",\n",
        "                \"positive_percentage\": np.nan,\n",
        "                \"magnitude\": np.nan,\n",
        "                \"error\": repr(e),\n",
        "            }\n",
        "        )\n",
        "        print(f\"[WARN] Failed on utt_id={utt_id}: {e}\")\n",
        "\n",
        "    # Checkpoint by sample count\n",
        "    if (n_done + n_failed) % CHECKPOINT_EVERY_N == 0 and rows_buffer:\n",
        "        chunk_df = pd.DataFrame(rows_buffer)\n",
        "        write_header = not PARTIAL_CSV.exists()\n",
        "        chunk_df.to_csv(PARTIAL_CSV, mode=\"a\", index=False, header=write_header)\n",
        "        rows_buffer = []\n",
        "        elapsed = time.time() - start_time\n",
        "        progress = {\n",
        "            \"n_total_iter_rows\": int(n_total),\n",
        "            \"n_done\": int(n_done),\n",
        "            \"n_skipped_resume\": int(n_skipped),\n",
        "            \"n_failed\": int(n_failed),\n",
        "            \"elapsed_sec\": float(elapsed),\n",
        "            \"partial_csv\": str(PARTIAL_CSV),\n",
        "        }\n",
        "        PROGRESS_JSON.write_text(json.dumps(progress, indent=2), encoding=\"utf-8\")\n",
        "        print(\n",
        "            f\"[CHKPT] done={n_done} skipped={n_skipped} failed={n_failed} elapsed={elapsed/60:.1f} min\"\n",
        "        )\n",
        "\n",
        "# Flush remaining rows\n",
        "if rows_buffer:\n",
        "    chunk_df = pd.DataFrame(rows_buffer)\n",
        "    write_header = not PARTIAL_CSV.exists()\n",
        "    chunk_df.to_csv(PARTIAL_CSV, mode=\"a\", index=False, header=write_header)\n",
        "    rows_buffer = []\n",
        "\n",
        "print(\"Scoring loop complete.\")\n",
        "print(\"done =\", n_done, \"| skipped =\", n_skipped, \"| failed =\", n_failed)\n",
        "print(\"Partial CSV =\", PARTIAL_CSV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Partial df_tcav shape: (6400, 17)\n",
            "Saved error rows -> /home/SpeakerRec/BioVoice/data/tcav/ASVspoof5_train_only_stage4_spoofwrapper/ASVspoof5_train_only_stage4_spoofwrapper__errors.csv | count = 6400\n",
            "Saved final CSV -> /home/SpeakerRec/BioVoice/data/tcav/ASVspoof5_train_only_stage4_spoofwrapper/ASVspoof5_train_only_stage4_spoofwrapper.csv\n",
            "Final shape: (0, 18)\n",
            "Sanity checks:\n",
            "Unique utt_id: 0\n",
            "Rows per utt (value counts):\n",
            "Series([], dtype: int64)\n",
            "Labels: {}\n",
            "Groups: {}\n",
            "Spoof systems in scored rows: []\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_index</th>\n",
              "      <th>utt_id</th>\n",
              "      <th>group</th>\n",
              "      <th>partition</th>\n",
              "      <th>speaker_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>label_str</th>\n",
              "      <th>label_id</th>\n",
              "      <th>system_id</th>\n",
              "      <th>target_class_name</th>\n",
              "      <th>target_class_id</th>\n",
              "      <th>layer_key</th>\n",
              "      <th>concept_name</th>\n",
              "      <th>layer_name</th>\n",
              "      <th>positive_percentage</th>\n",
              "      <th>magnitude</th>\n",
              "      <th>cav_acc</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [row_index, utt_id, group, partition, speaker_id, gender, label_str, label_id, system_id, target_class_name, target_class_id, layer_key, concept_name, layer_name, positive_percentage, magnitude, cav_acc, error]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Finalize CSV: merge CAV accuracies, save final file, and sanity checks\n",
        "assert PARTIAL_CSV.exists(), f'Missing partial CSV: {PARTIAL_CSV}'\n",
        "df_tcav = pd.read_csv(PARTIAL_CSV)\n",
        "print('Partial df_tcav shape:', df_tcav.shape)\n",
        "\n",
        "# Remove error rows from final scoring CSV (keep them separately if needed)\n",
        "if 'error' in df_tcav.columns:\n",
        "    err_rows = df_tcav[df_tcav['layer_key'] == 'ERROR'].copy()\n",
        "    if not err_rows.empty:\n",
        "        err_csv = RUN_DIR / f'{RUN_TAG}__errors.csv'\n",
        "        err_rows.to_csv(err_csv, index=False)\n",
        "        print('Saved error rows ->', err_csv, '| count =', len(err_rows))\n",
        "    df_tcav = df_tcav[df_tcav['layer_key'] != 'ERROR'].copy()\n",
        "\n",
        "if not acc_df_combined.empty:\n",
        "    df_tcav = df_tcav.merge(\n",
        "        acc_df_combined,\n",
        "        on=['layer_key', 'concept_name', 'layer_name'],\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "# Consistent final column names (underscore style)\n",
        "final_cols = [\n",
        "    'row_index','utt_id','group','partition','speaker_id','gender',\n",
        "    'label_str','label_id','system_id','target_class_name','target_class_id',\n",
        "    'layer_key','concept_name','layer_name','positive_percentage','magnitude','cav_acc'\n",
        "]\n",
        "extra_cols = [c for c in df_tcav.columns if c not in final_cols]\n",
        "df_tcav = df_tcav[[c for c in final_cols if c in df_tcav.columns] + extra_cols]\n",
        "\n",
        "df_tcav.to_csv(FINAL_CSV, index=False)\n",
        "print('Saved final CSV ->', FINAL_CSV)\n",
        "print('Final shape:', df_tcav.shape)\n",
        "\n",
        "print('Sanity checks:')\n",
        "print('Unique utt_id:', df_tcav['utt_id'].nunique())\n",
        "print('Rows per utt (value counts):')\n",
        "print(df_tcav.groupby('utt_id').size().value_counts().sort_index())\n",
        "print('Labels:', df_tcav[['utt_id','label_str']].drop_duplicates()['label_str'].value_counts().to_dict())\n",
        "print('Groups:', df_tcav[['utt_id','group']].drop_duplicates()['group'].value_counts().to_dict())\n",
        "print('Spoof systems in scored rows:', sorted(df_tcav.loc[df_tcav['label_str']=='spoof','system_id'].astype(str).unique().tolist())[:20])\n",
        "\n",
        "display(df_tcav.head(20))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
