{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) ENV + Imports\n",
    "# =========================\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "\n",
    "os.environ[\"COQUI_TOS_AGREED\"] = \"1\"\n",
    "os.environ[\"COQUI_TTS_AGREED\"] = \"1\"\n",
    "\n",
    "from TTS.api import TTS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Paths + Globals\n",
    "# =========================\n",
    "DATA_DIR = Path(\"/home/SpeakerRec/BioVoice/data/\")\n",
    "WAVS_DIR = DATA_DIR / \"wavs\"\n",
    "\n",
    "TTS_DIR = DATA_DIR / \"tts\" / \"coqui\"\n",
    "TTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PREP_DIR = TTS_DIR / \"_prepared_refs\"\n",
    "PREP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
    "LANGUAGE = \"en\"\n",
    "\n",
    "TRIM_REF_SECONDS = 6.0\n",
    "NORMALIZE_REF = True\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "\n",
    "print(\"CUDA available:\", USE_GPU)\n",
    "print(\"TTS_DIR:\", TTS_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Sentences (1..30)\n",
    "# =========================\n",
    "SENTENCES: list[str] = [\n",
    "    \"My voice is my password.\",\n",
    "    \"Verify me with my voice.\",\n",
    "    \"Authenticate this speaker, please.\",\n",
    "    \"Grant access to my account.\",\n",
    "    \"Unlock the system for me.\",\n",
    "    \"Confirm my identity by voice.\",\n",
    "    \"This is my secret phrase.\",\n",
    "    \"Secure login with my voice.\",\n",
    "    \"Trust but verify my speech.\",\n",
    "    \"Match this voice to me.\",\n",
    "    \"Approve access for this speaker.\",\n",
    "    \"Voice check for my login.\",\n",
    "    \"Identity check, voice only.\",\n",
    "    \"Compare my voiceprint now.\",\n",
    "    \"Validate this voice as mine.\",\n",
    "    \"I request secure entry.\",\n",
    "    \"Open my profile securely.\",\n",
    "    \"Allow login after verification.\",\n",
    "    \"Voice key engaged, confirm.\",\n",
    "    \"Check phrase against enrollment.\",\n",
    "    \"This utterance authenticates me.\",\n",
    "    \"Biometric login, voice sample.\",\n",
    "    \"Authenticate this session, please.\",\n",
    "    \"Approve sign-in by voice.\",\n",
    "    \"Access gate, verify speaker.\",\n",
    "    \"This is my access phrase.\",\n",
    "    \"Confirm speaker equals account owner.\",\n",
    "    \"Match phrase to enrolled sample.\",\n",
    "    \"Security check, no typed password.\",\n",
    "    \"Thank you for verification.\",\n",
    "]\n",
    "assert len(SENTENCES) == 30\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Speaker refs (2 each) + picking logic\n",
    "# =========================\n",
    "SPEAKER_REFS: dict[str, list[Path]] = {\n",
    "    \"idan\": [WAVS_DIR / \"idan_001.wav\", WAVS_DIR / \"idan_002.wav\"],\n",
    "    \"yoav\": [WAVS_DIR / \"yoav_001.wav\", WAVS_DIR / \"yoav_002.wav\"],\n",
    "    \"eden\": [WAVS_DIR / \"eden_001.wav\", WAVS_DIR / \"eden_002.wav\"],\n",
    "}\n",
    "\n",
    "for spk, refs in SPEAKER_REFS.items():\n",
    "    assert len(refs) == 2, f\"{spk} must have exactly 2 ref wavs\"\n",
    "    for r in refs:\n",
    "        assert r.exists(), f\"Missing ref wav: {r}\"\n",
    "\n",
    "def pick_ref_for_sentence(refs: list[Path], sentence_idx_1based: int) -> Path:\n",
    "    # ref #1 for 1..15, ref #2 for 16..30\n",
    "    return refs[0] if sentence_idx_1based <= 15 else refs[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Prepare ref wavs (soundfile; no torchaudio dependency)\n",
    "# =========================\n",
    "def prepare_ref_wav(\n",
    "    in_wav: Path,\n",
    "    out_wav: Path,\n",
    "    *,\n",
    "    trim_seconds: float | None = None,\n",
    "    normalize: bool = True,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Loads with soundfile, converts to mono, trims, normalizes, saves float32 wav.\n",
    "    \"\"\"\n",
    "    audio, sr = sf.read(in_wav.as_posix(), dtype=\"float32\", always_2d=True)  # [T, C]\n",
    "    mono = audio.mean(axis=1)  # [T]\n",
    "\n",
    "    if trim_seconds is not None and trim_seconds > 0:\n",
    "        n = int(trim_seconds * sr)\n",
    "        mono = mono[:n]\n",
    "\n",
    "    if normalize:\n",
    "        peak = float(np.max(np.abs(mono)) + 1e-8)\n",
    "        mono = (mono / peak) * 0.95\n",
    "\n",
    "    sf.write(out_wav.as_posix(), mono, sr)\n",
    "    return out_wav\n",
    "\n",
    "# prepare refs once\n",
    "PREP_REFS: dict[Path, Path] = {}\n",
    "for spk, refs in SPEAKER_REFS.items():\n",
    "    for r in refs:\n",
    "        out = PREP_DIR / f\"{r.stem}_prep.wav\"\n",
    "        if not out.exists():\n",
    "            prepare_ref_wav(r, out, trim_seconds=TRIM_REF_SECONDS, normalize=NORMALIZE_REF)\n",
    "        PREP_REFS[r] = out\n",
    "\n",
    "print(\"Prepared refs:\")\n",
    "for k, v in PREP_REFS.items():\n",
    "    print(\" \", k.name, \"->\", v.name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Load XTTS model once\n",
    "# =========================\n",
    "tts = TTS(MODEL_NAME, gpu=USE_GPU)\n",
    "print(\"Loaded:\", MODEL_NAME)\n",
    "\n",
    "# optional: check output sample rate if exposed\n",
    "sr_out = getattr(getattr(tts, \"synthesizer\", None), \"output_sample_rate\", None)\n",
    "print(\"Output SR (if known):\", sr_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Batch generate (same as F5)\n",
    "# =========================\n",
    "manifest_path = TTS_DIR / \"manifest.csv\"\n",
    "rows: list[dict[str, str]] = []\n",
    "\n",
    "total = 0\n",
    "failed = 0\n",
    "t0 = time.time()\n",
    "\n",
    "for speaker, refs in SPEAKER_REFS.items():\n",
    "    for i, gen_text in enumerate(SENTENCES, start=1):\n",
    "        ref_wav = pick_ref_for_sentence(refs, i)\n",
    "        ref_prepared = PREP_REFS[ref_wav]\n",
    "\n",
    "        out_wav = TTS_DIR / f\"{speaker}_{i:02d}.wav\"\n",
    "\n",
    "        try:\n",
    "            # XTTS-v2: reference voice is speaker_wav\n",
    "            tts.tts_to_file(\n",
    "                text=gen_text,\n",
    "                speaker_wav=ref_prepared.as_posix(),\n",
    "                language=LANGUAGE,\n",
    "                file_path=out_wav.as_posix(),\n",
    "            )\n",
    "\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"speaker\": speaker,\n",
    "                    \"sentence_idx\": str(i),\n",
    "                    \"gen_text\": gen_text,\n",
    "                    \"ref_wav\": str(ref_wav),\n",
    "                    \"ref_prepared\": str(ref_prepared),\n",
    "                    \"out_wav\": str(out_wav),\n",
    "                    \"model_name\": MODEL_NAME,\n",
    "                    \"language\": LANGUAGE,\n",
    "                    \"ok\": \"1\",\n",
    "                    \"error\": \"\",\n",
    "                }\n",
    "            )\n",
    "            total += 1\n",
    "            print(f\"[OK] {speaker} {i:02d}/30 -> {out_wav.name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            failed += 1\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"speaker\": speaker,\n",
    "                    \"sentence_idx\": str(i),\n",
    "                    \"gen_text\": gen_text,\n",
    "                    \"ref_wav\": str(ref_wav),\n",
    "                    \"ref_prepared\": str(ref_prepared),\n",
    "                    \"out_wav\": str(out_wav),\n",
    "                    \"model_name\": MODEL_NAME,\n",
    "                    \"language\": LANGUAGE,\n",
    "                    \"ok\": \"0\",\n",
    "                    \"error\": repr(e),\n",
    "                }\n",
    "            )\n",
    "            print(f\"[FAIL] {speaker} {i:02d}/30 -> {out_wav.name} | {e}\")\n",
    "\n",
    "with open(manifest_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(\n",
    "        f,\n",
    "        fieldnames=[\n",
    "            \"speaker\",\n",
    "            \"sentence_idx\",\n",
    "            \"gen_text\",\n",
    "            \"ref_wav\",\n",
    "            \"ref_prepared\",\n",
    "            \"out_wav\",\n",
    "            \"model_name\",\n",
    "            \"language\",\n",
    "            \"ok\",\n",
    "            \"error\",\n",
    "        ],\n",
    "    )\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "dt = time.time() - t0\n",
    "print(f\"\\nDone. ok={total} failed={failed} time_sec={dt:.1f}\")\n",
    "print(\"Manifest:\", manifest_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Quick preview\n",
    "# =========================\n",
    "Audio(str(TTS_DIR / \"yoav_01.wav\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
