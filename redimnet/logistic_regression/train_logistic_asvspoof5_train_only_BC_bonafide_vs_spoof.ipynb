{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASVspoof5 Train-Only Probe (B -> C): Bonafide vs Spoof\n",
    "\n",
    "This notebook trains a `StandardScaler + LogisticRegression` probe on **ReDimNet embeddings** using the ASVspoof5 train-only subset with the fixed speaker split:\n",
    "\n",
    "- Train: `group B` (15 speakers)\n",
    "- Test: `group C` (5 speakers)\n",
    "- Labels: `0=bonafide`, `1=spoof`\n",
    "\n",
    "This is the clean baseline probe for the train-only subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "PROJECT_ROOT = Path(\"/home/SpeakerRec/BioVoice\")\n",
    "MANIFEST_PATH = PROJECT_ROOT / \"redimnet\" / \"tcav\" / \"deepfakes\" / \"asvspoof5\" / \"asvspoof5_train_only_selected_utterances_plan.csv\"\n",
    "SUBSET_AUDIO_ROOT = PROJECT_ROOT / \"data\" / \"datasets\" / \"asvspoof5_train_only_subset_audio\"\n",
    "\n",
    "EMBED_CACHE_DIR = PROJECT_ROOT / \"data\" / \"embeddings\" / \"asvspoof5_train_only_abc\"\n",
    "EMBED_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "print(\"MANIFEST_PATH:\", MANIFEST_PATH)\n",
    "print(\"SUBSET_AUDIO_ROOT:\", SUBSET_AUDIO_ROOT)\n",
    "\n",
    "OUT_DIR = PROJECT_ROOT / 'data' / 'models' / 'asvspoof5_train_only_probe_BC_global'\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CACHE_NPZ = EMBED_CACHE_DIR / 'embeddings_BC_global.npz'\n",
    "FORCE_RECOMPUTE_EMBEDDINGS = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_MAP = {\"bonafide\": 0, \"spoof\": 1}\n",
    "\n",
    "\n",
    "def build_audio_path(row, subset_root: Path) -> Path:\n",
    "    # extracted subset layout: <root>/<group>/<label>/<utt_id>.flac\n",
    "    return subset_root / str(row[\"group\"]) / str(row[\"label\"]) / f\"{row['utt_id']}.flac\"\n",
    "\n",
    "\n",
    "def load_manifest(manifest_path: Path, subset_root: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(manifest_path)\n",
    "    req = {\"group\", \"speaker_id\", \"utt_id\", \"label\", \"system_id\"}\n",
    "    missing = req - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Manifest missing columns: {sorted(missing)}\")\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"label_str\"] = df[\"label\"].astype(str)\n",
    "    df[\"label_id\"] = df[\"label_str\"].map(LABEL_MAP).astype(int)\n",
    "    df[\"audio_path\"] = df.apply(lambda r: str(build_audio_path(r, subset_root)), axis=1)\n",
    "    df[\"audio_exists\"] = df[\"audio_path\"].map(lambda p: Path(p).exists())\n",
    "    return df\n",
    "\n",
    "\n",
    "def embed_with_redim(model, wav_path: str, device: str) -> np.ndarray:\n",
    "    wav, sr = torchaudio.load(wav_path)\n",
    "    if sr != 16000:\n",
    "        wav = torchaudio.functional.resample(wav, sr, 16000)\n",
    "    if wav.shape[0] > 1:\n",
    "        wav = wav[:1, :]\n",
    "    wav = wav.to(device)\n",
    "    with torch.no_grad():\n",
    "        emb = model(wav)\n",
    "    return emb.squeeze(0).detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "\n",
    "def extract_embeddings_for_df(df: pd.DataFrame, model, device: str, cache_npz: Path, force_recompute: bool = False):\n",
    "    if cache_npz.exists() and not force_recompute:\n",
    "        payload = np.load(cache_npz, allow_pickle=True)\n",
    "        emb = payload[\"X\"]\n",
    "        utt_ids = payload[\"utt_ids\"].astype(str)\n",
    "        cache_df = pd.DataFrame({\"utt_id\": utt_ids, \"_emb_idx\": np.arange(len(utt_ids))})\n",
    "        merged = df.merge(cache_df, on=\"utt_id\", how=\"left\", validate=\"one_to_one\")\n",
    "        if merged[\"_emb_idx\"].isna().any():\n",
    "            missing = merged.loc[merged[\"_emb_idx\"].isna(), \"utt_id\"].tolist()[:10]\n",
    "            raise RuntimeError(f\"Cache missing utt_ids, examples: {missing}\")\n",
    "        X = emb[merged[\"_emb_idx\"].astype(int).to_numpy()]\n",
    "        return X\n",
    "\n",
    "    rows = []\n",
    "    vecs = []\n",
    "    for rec in tqdm(df.to_dict(\"records\"), desc=f\"Embedding {len(df)} samples\"):\n",
    "        p = Path(rec[\"audio_path\"])\n",
    "        if not p.exists():\n",
    "            raise FileNotFoundError(f\"Missing audio: {p}\")\n",
    "        vecs.append(embed_with_redim(model, str(p), device))\n",
    "        rows.append(str(rec[\"utt_id\"]))\n",
    "    X = np.stack(vecs).astype(np.float32)\n",
    "    np.savez_compressed(cache_npz, X=X, utt_ids=np.array(rows, dtype=object))\n",
    "    return X\n",
    "\n",
    "\n",
    "def train_and_eval_logreg(X_train, y_train, X_test, y_test, class_weight=\"balanced\"):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=2000, class_weight=class_weight, random_state=42)\n",
    "    clf.fit(X_train_s, y_train)\n",
    "\n",
    "    p_train = clf.predict_proba(X_train_s)[:, 1]\n",
    "    p_test = clf.predict_proba(X_test_s)[:, 1]\n",
    "    yhat_train = (p_train >= 0.5).astype(int)\n",
    "    yhat_test = (p_test >= 0.5).astype(int)\n",
    "\n",
    "    metrics = {\n",
    "        \"train_accuracy\": float(accuracy_score(y_train, yhat_train)),\n",
    "        \"test_accuracy\": float(accuracy_score(y_test, yhat_test)),\n",
    "        \"train_auc\": float(roc_auc_score(y_train, p_train)) if len(np.unique(y_train)) == 2 else None,\n",
    "        \"test_auc\": float(roc_auc_score(y_test, p_test)) if len(np.unique(y_test)) == 2 else None,\n",
    "        \"train_confusion_matrix\": confusion_matrix(y_train, yhat_train).tolist(),\n",
    "        \"test_confusion_matrix\": confusion_matrix(y_test, yhat_test).tolist(),\n",
    "        \"train_classification_report\": classification_report(y_train, yhat_train, output_dict=True, zero_division=0),\n",
    "        \"test_classification_report\": classification_report(y_test, yhat_test, output_dict=True, zero_division=0),\n",
    "    }\n",
    "    return scaler, clf, X_train_s, X_test_s, p_train, p_test, yhat_train, yhat_test, metrics\n",
    "\n",
    "\n",
    "def plot_confmat(cm, title):\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    im = ax.imshow(cm, cmap=\"Blues\")\n",
    "    ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "    ax.set_xticklabels([\"bonafide\",\"spoof\"], rotation=30, ha=\"right\")\n",
    "    ax.set_yticklabels([\"bonafide\",\"spoof\"])\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(title)\n",
    "    for (i,j), v in np.ndenumerate(cm):\n",
    "        ax.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
    "    plt.colorbar(im, ax=ax, fraction=0.046)\n",
    "    plt.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ReDimNet backbone for embedding extraction\n",
    "redim_model = (\n",
    "    torch.hub.load(\n",
    "        \"IDRnD/ReDimNet\",\n",
    "        \"ReDimNet\",\n",
    "        model_name=\"b5\",\n",
    "        train_type=\"ptn\",\n",
    "        dataset=\"vox2\",\n",
    "    )\n",
    "    .to(DEVICE)\n",
    "    .eval()\n",
    ")\n",
    "print(\"Loaded ReDimNet on\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load manifest and build B/C split\n",
    "manifest_df = load_manifest(MANIFEST_PATH, SUBSET_AUDIO_ROOT)\n",
    "print(\"Manifest rows:\", len(manifest_df))\n",
    "print(\"Missing audio paths:\", int((~manifest_df['audio_exists']).sum()))\n",
    "\n",
    "bc_df = manifest_df[manifest_df['group'].isin(['B','C'])].copy().reset_index(drop=True)\n",
    "print(\"B/C rows:\", len(bc_df))\n",
    "print(bc_df.groupby(['group','label_str']).size().unstack(fill_value=0))\n",
    "print(\"Unique B speakers:\", bc_df.loc[bc_df.group=='B','speaker_id'].nunique())\n",
    "print(\"Unique C speakers:\", bc_df.loc[bc_df.group=='C','speaker_id'].nunique())\n",
    "\n",
    "X_bc = extract_embeddings_for_df(bc_df[['utt_id','audio_path']], redim_model, DEVICE, CACHE_NPZ, force_recompute=FORCE_RECOMPUTE_EMBEDDINGS)\n",
    "y_bc = bc_df['label_id'].to_numpy().astype(int)\n",
    "\n",
    "train_mask = bc_df['group'].eq('B').to_numpy()\n",
    "test_mask = bc_df['group'].eq('C').to_numpy()\n",
    "\n",
    "X_train, y_train = X_bc[train_mask], y_bc[train_mask]\n",
    "X_test, y_test = X_bc[test_mask], y_bc[test_mask]\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, clf, X_train_s, X_test_s, p_train, p_test, yhat_train, yhat_test, metrics = train_and_eval_logreg(\n",
    "    X_train, y_train, X_test, y_test, class_weight='balanced'\n",
    ")\n",
    "\n",
    "print(json.dumps({k:v for k,v in metrics.items() if 'report' not in k}, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model + metrics + predictions\n",
    "with open(OUT_DIR / 'scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open(OUT_DIR / 'logistic_regression.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "(OUT_DIR / 'metrics.json').write_text(json.dumps(metrics, indent=2), encoding='utf-8')\n",
    "\n",
    "pred_df = bc_df[['group','speaker_id','utt_id','label_str','label_id','system_id']].copy()\n",
    "pred_df['split'] = np.where(train_mask, 'train_B', 'test_C')\n",
    "pred_df['prob_spoof'] = np.concatenate([p_train, p_test])\n",
    "pred_df['pred_label_id'] = np.concatenate([yhat_train, yhat_test])\n",
    "pred_df['pred_label_str'] = pred_df['pred_label_id'].map({0:'bonafide',1:'spoof'})\n",
    "pred_df.to_csv(OUT_DIR / 'predictions_BC_global.csv', index=False)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature_index': np.arange(clf.coef_.shape[1]),\n",
    "    'coefficient': clf.coef_.ravel(),\n",
    "    'abs_coefficient': np.abs(clf.coef_.ravel()),\n",
    "}).sort_values('abs_coefficient', ascending=False)\n",
    "coef_df.to_csv(OUT_DIR / 'coefficients.csv', index=False)\n",
    "\n",
    "print('Saved outputs ->', OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots: train/test accuracy + confusion matrix + probability histograms\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "ax.bar(['Train (B)','Test (C)'], [metrics['train_accuracy'], metrics['test_accuracy']], color=['#4e79a7','#f28e2b'])\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('B -> C Accuracy')\n",
    "for i,v in enumerate([metrics['train_accuracy'], metrics['test_accuracy']]):\n",
    "    ax.text(i, v+0.02, f'{v:.3f}', ha='center')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "cm_fig = plot_confmat(np.array(metrics['test_confusion_matrix']), 'Test (C) Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.hist(p_train[y_train==0], bins=20, alpha=0.5, label='Train bonafide')\n",
    "ax.hist(p_train[y_train==1], bins=20, alpha=0.5, label='Train spoof')\n",
    "ax.hist(p_test[y_test==0], bins=20, alpha=0.5, label='Test bonafide')\n",
    "ax.hist(p_test[y_test==1], bins=20, alpha=0.5, label='Test spoof')\n",
    "ax.set_xlabel('P(spoof)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Train/Test Probability Distributions')\n",
    "ax.legend(fontsize=8)\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}