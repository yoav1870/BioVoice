{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# 3. Visualization and Interpretation\n",
        "\n",
        "This notebook reads the outputs from the training notebook and shows:\n",
        "- global concept importance\n",
        "- fake vs real concept summaries\n",
        "- per-user important concepts (test speakers)\n",
        "- plots / heatmaps\n",
        "\n",
        "This notebook is self-contained and does not import the `.py` script.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "PROJECT_ROOT = Path('/home/SpeakerRec/BioVoice')\n",
        "ANALYSIS_DIR = PROJECT_ROOT / 'data' / 'tcav' / 'logreg_concept_analysis' / 'stage4_spoofwrapper_pospct'\n",
        "PLOTS_DIR = ANALYSIS_DIR / 'plots'\n",
        "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print('ANALYSIS_DIR =', ANALYSIS_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Load exported analysis files\n",
        "paths = {\n",
        "    'meta': ANALYSIS_DIR / 'run_metadata.json',\n",
        "    'coef': ANALYSIS_DIR / 'global_concept_coefficients.csv',\n",
        "    'class_summary': ANALYSIS_DIR / 'classwise_concept_summary.csv',\n",
        "    'preds': ANALYSIS_DIR / 'test_predictions.csv',\n",
        "    'user_contrib': ANALYSIS_DIR / 'test_user_mean_contributions.csv',\n",
        "    'top_user': ANALYSIS_DIR / 'test_user_top_concepts.csv',\n",
        "}\n",
        "for k, p in paths.items():\n",
        "    assert p.exists(), f'Missing file for {k}: {p}'\n",
        "\n",
        "run_meta = json.loads(paths['meta'].read_text(encoding='utf-8'))\n",
        "coef_df = pd.read_csv(paths['coef'])\n",
        "class_summary_df = pd.read_csv(paths['class_summary'])\n",
        "pred_df = pd.read_csv(paths['preds'])\n",
        "user_contrib = pd.read_csv(paths['user_contrib'])\n",
        "top_user_df = pd.read_csv(paths['top_user'])\n",
        "\n",
        "print('Loaded files successfully')\n",
        "print('Train speakers:', run_meta['speaker_split']['train_speakers'])\n",
        "print('Test speakers :', run_meta['speaker_split']['test_speakers'])\n",
        "print('Metrics:')\n",
        "print(json.dumps({k:v for k,v in run_meta['metrics'].items() if k != 'classification_report'}, indent=2))\n",
        "print(run_meta['metrics']['classification_report'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Tables: global importance + class-wise differences\n",
        "print('Top global coefficients (absolute):')\n",
        "display(coef_df.head(20))\n",
        "\n",
        "print('Top concepts higher in fake (mean difference fake-real):')\n",
        "display(class_summary_df.sort_values('mean_diff_fake_minus_real', ascending=False).head(15))\n",
        "\n",
        "print('Top concepts higher in real (mean difference fake-real most negative):')\n",
        "display(class_summary_df.sort_values('mean_diff_fake_minus_real', ascending=True).head(15))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Table: per-user important concepts on test speakers\n",
        "# list_type = top_fake_supporting / top_real_supporting\n",
        "for spk in sorted(top_user_df['speaker_id'].astype(str).unique().tolist()):\n",
        "    print('\\n===', spk, '===')\n",
        "    display(top_user_df[top_user_df['speaker_id'] == spk].sort_values(['true label', 'list_type', 'rank']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Plot 1: Global coefficient bar chart (top 20 by absolute value)\n",
        "plot_df = coef_df.head(20).copy().iloc[::-1]\n",
        "colors = ['#b2182b' if d == 'fake' else '#2166ac' if d == 'real' else '#666666' for d in plot_df['direction']]\n",
        "\n",
        "plt.figure(figsize=(10, max(6, 0.35 * len(plot_df))))\n",
        "plt.barh(plot_df['feature'], plot_df['coefficient'], color=colors)\n",
        "plt.axvline(0, color='black', linewidth=1)\n",
        "plt.title('Global Logistic Coefficients (positive=fake, negative=real)')\n",
        "plt.tight_layout()\n",
        "plt.savefig(PLOTS_DIR / 'global_coefficients_top20.png', dpi=150)\n",
        "plt.show()\n",
        "print('Saved:', PLOTS_DIR / 'global_coefficients_top20.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Plot 2: Per-user heatmap (fake samples only, mean contributions)\n",
        "fake_user = user_contrib[user_contrib['true label'] == 1].copy()\n",
        "if fake_user.empty:\n",
        "    print('No fake samples in test user contributions.')\n",
        "else:\n",
        "    heat = fake_user.pivot_table(index='speaker_id', columns='feature', values='mean_contribution', aggfunc='mean')\n",
        "    test_speakers = run_meta['speaker_split']['test_speakers']\n",
        "    heat = heat.loc[[s for s in test_speakers if s in heat.index]]\n",
        "    heat = heat.fillna(0)\n",
        "\n",
        "    plt.figure(figsize=(max(10, 0.45 * heat.shape[1]), max(4, 0.6 * heat.shape[0])))\n",
        "    im = plt.imshow(heat.to_numpy(), aspect='auto', cmap='coolwarm')\n",
        "    plt.colorbar(im, label='Mean contribution')\n",
        "    plt.xticks(range(heat.shape[1]), heat.columns, rotation=90, fontsize=8)\n",
        "    plt.yticks(range(heat.shape[0]), heat.index, fontsize=9)\n",
        "    plt.title('Per-user Mean Concept Contributions (Fake Samples Only)')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(PLOTS_DIR / 'user_heatmap_fake_samples.png', dpi=150)\n",
        "    plt.show()\n",
        "    print('Saved:', PLOTS_DIR / 'user_heatmap_fake_samples.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Optional: summary of which concepts recur most often in top-k lists across users\n",
        "freq = (\n",
        "    top_user_df.groupby(['list_type', 'concept']).size().reset_index(name='count')\n",
        "    .sort_values(['list_type', 'count', 'concept'], ascending=[True, False, True])\n",
        ")\n",
        "display(freq)\n",
        "freq.to_csv(ANALYSIS_DIR / 'top_concept_frequency_across_users.csv', index=False)\n",
        "print('Saved:', ANALYSIS_DIR / 'top_concept_frequency_across_users.csv')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}